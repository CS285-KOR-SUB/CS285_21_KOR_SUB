1
00:00:00,390 --> 00:00:03,600
자, 이제 pytorch의 기초에 대해 이야기를 시작하겠습니다.

2
00:00:03,600 --> 00:00:06,310
pytorch는 텐서를 중심으로 구축됩니다.

3
00:00:06,310 --> 00:00:08,400
numpy 배열과 정말 유사합니다.

4
00:00:08,400 --> 00:00:16,400
그리고 기본적으로 이전 비디오에서 numpy로 이야기한 많은 것들이 pytorch 텐서에서도 똑같은 일을 할 수 있습니다.

5
00:00:16,400 --> 00:00:24,000
예를 들어 모양이 같은 두 개의 pytorch 텐서를 정의한 다음 numpy 배열에서 했던 것처럼 함께 추가할 수 있습니다.

6
00:00:24,000 --> 00:00:30,640
또한 numpy에서 하는 것처럼 축소를 수행할 수 있으며 해당 축소를 수행하려는 축을 지정할 수 있습니다.

7
00:00:30,640 --> 00:00:39,520
pytorch에서 인수는 axes 대신 dimesion(차원)이라는 의미로 dim이라고 하지만 다른 것은 동일합니다.

8
00:00:39,520 --> 00:00:43,680
numpy pytorch와 마찬가지로 가능한 경우 브로드캐스트 작업도 시도합니다.

9
00:00:43,680 --> 00:00:51,920
따라서 다른 모양의 이 두 텐서가 있으면 브로드캐스트될 것이기 때문에 여전히 함께 추가할 수 있습니다.

10
00:00:51,920 --> 00:00:56,800
아마도 꽤 자주 할 일은 numpy 배열과 pytorch 텐서간의 변환을하는 것입니다.

11
00:00:56,800 --> 00:01:01,600
그것이 왜 필요한지에 대해서는 잠시 후에 더 이야기할 것입니다.

12
00:01:01,600 --> 00:01:04,550
하지만 지금은 작동 방식을 보여 드리겠습니다.

13
00:01:04,550 --> 00:01:08,150
이 numpy 배열이 있다고 가정 해 봅시다.

14
00:01:08,150 --> 00:01:12,640
2 x 3이고 이것을 pytorch 텐서로 변환하고 싶습니다.

15
00:01:12,640 --> 00:01:15,750
그렇게 하기 위해 저는 torch.from numpy 함수를 사용할 것입니다.

16
00:01:15,750 --> 00:01:19,840
그리고 그것이 하는 일은 나에게 새로운 pytorch 텐서를 제공한다는 것입니다.

17
00:01:19,840 --> 00:01:24,400
그러나 그 텐서는 실제로 원래 numpy 배열과 동일한 메모리를 공유합니다.

18
00:01:24,400 --> 00:01:29,430
따라서 이 새로운 텐서 x에서 모든 종류의 pytorch 작업을 지금 수행할 수 있지만

19
00:01:29,430 --> 00:01:33,600
그것은 실제로 메모리의 동일한 부분을 참조하고 있습니다

20
00:01:33,600 --> 00:01:36,070
따라서 원래 numpy 배열을 변경하면

21
00:01:36,070 --> 00:01:43,040
그것은 또한 pytorch 텐서에 영향을 미치고 그 반대의 경우도 마찬가지입니다.

22
00:01:43,040 --> 00:01:46,640
기본적으로 numpy 배열은 float 64 유형이 됩니다.

23
00:01:46,640 --> 00:01:50,720
따라서 pytorch 텐서를 출력할 때마다 이 dtype 속성을 보면

24
00:01:50,720 --> 00:01:54,560
어떤 데이터 유형인지 알 수 있습니다

25
00:01:54,560 --> 00:01:58,470
대부분의 경우 텐서와 파이 토치는 실제로 float32입니다.

26
00:01:58,470 --> 00:02:00,390
그래서 numpy에서 pytorch로 변환할 때

27
00:02:00,390 --> 00:02:04,960
실제로 float32 유형으로 캐스팅하고 싶을 것입니다.

28
00:02:04,960 --> 00:02:07,680
추가 정밀도 수준이 실제로 필요하지 않기 때문에

29
00:02:07,680 --> 00:02:13,590
그래서 당신이하는 방법은 점을 호출하고 부동 정수 또는 원하는 것을 지정할 수 있다는 것입니다.

30
00:02:13,590 --> 00:02:20,080
다른 데이터 유형으로 변경하는 방법입니다.

31
00:02:20,080 --> 00:02:24,000
여기에서는 기본적으로 기본 부동 소수점 유형으로 변환했기 때문에

32
00:02:24,000 --> 00:02:28,480
dtype이 지정되지 않은 것을 볼 수 있습니다.

33
00:02:28,480 --> 00:02:31,200
마지막으로 pytorch 텐서가 있는 경우 다른 방향으로 가고 싶다면

34
00:02:31,200 --> 00:02:33,040
numpy 배열로 돌아가고 싶을 때는 어떻게 할까요?

35
00:02:33,040 --> 00:02:36,800
그 텐서에 점을 찍어 numpy를 호출 할 수 있습니다.

36
00:02:36,800 --> 00:02:45,200
다시 이것은 메모리의 동일한 부분을 차지하므로 하나를 변경하면 다른 하나가 변경됩니다.

37
00:02:45,200 --> 00:02:49,040
pytorch에는 신경망용 내장 함수도 많이 있습니다.

38
00:02:49,040 --> 00:02:52,230
이것은 당신이 그들을 훈련시킬 때 정말 유용할 수 있습니다

39
00:02:52,230 --> 00:02:55,510
당신이 할 수 있는 일의 전체 목록은 문서를 반드시 확인해야 합니다.

40
00:02:55,510 --> 00:03:00,150
기회는 당신이하려고하는 것이 무엇이든 pytorch에 이미 그것을 달성하는 무언가가 있습니다.

41
00:03:00,150 --> 00:03:04,080
하지만 얼마나 많은 것을 사용할 수 있는지에 대한 감각을 제공하기 위해

42
00:03:04,080 --> 00:03:09,510
relu sigmoid 10h와 같은 모든 종류의 활성화 함수에는 각각에 대한 함수가 있습니다.

43
00:03:09,510 --> 00:03:13,920
수행해야 하는 수치 최적화와 함께

44
00:03:13,920 --> 00:03:15,120
그래서 당신은 그것에 대해 걱정할 필요가 없습니다

45
00:03:15,120 --> 00:03:20,080
내장 토치 기능을 사용할 수 있습니다.

46
00:03:20,080 --> 00:03:24,310
확률을 예측하려는 경우 softmax 기능도 있습니다.

47
00:03:24,310 --> 00:03:31,360
일부 pytorch 텐서에서 softmax를 호출할 수 있습니다.

48
00:03:31,360 --> 00:03:40,150
차원이 음수와 같도록 이제 이것을 벗고 있습니다. 즉, 마지막 차원을 사용하고 있으므로 기본적으로 각 행은 일련의 확률이 될 것입니다.

49
00:03:40,150 --> 00:03:48,790
그런 다음 비틀림 소프트 맥스를 호출할 때 이 논리를 확률로 변환합니다.

50
00:03:48,790 --> 00:03:54,640
따라서 아마도 pytorch의 가장 중요한 부분은 자동 미분을 수행하는 방식일 것입니다.

51
00:03:54,640 --> 00:03:57,920
왜냐하면 당신이 손으로 역전파를 시도한 적이 있다면

52
00:03:57,920 --> 00:04:02,560
정말 지루하고 코드에서 구현하려고 하는 것이 아닙니다.

53
00:04:02,560 --> 00:04:10,150
이것은 신경망 훈련 측면에서 pytorch가 수행하는 가장 중요한 부분 중 하나입니다.

54
00:04:10,150 --> 00:04:18,070
손실 함수가 있고 입력 x 및 y에 대한 손실 함수의 기울기를 평가하려고 한다고 가정해 보겠습니다.

55
00:04:18,070 --> 00:04:24,800
따라서 추가로 지정할 수 있는 텐서를 정의할 때 값이 필요합니다. true

56
00:04:24,800 --> 00:04:30,630
그리고 그것은 기본적으로 pytorch에게 이 변수에 대한 그라디언트를 추적해야 한다고 알려줍니다.

57
00:04:30,630 --> 00:04:39,600
기본적으로 고정 텐서가 되도록 지정하지 않고 back prop에 대해 추적되는 그래디언트가 없는 경우

58
00:04:39,600 --> 00:04:47,520
따라서 require grad equals true를 지정하면 텐서가 두 가지 정보를 추적하게 됩니다.

59
00:04:47,520 --> 00:04:50,630
첫 번째는 텐서의 원래 값인 데이터입니다.

60
00:04:50,630 --> 00:04:55,120
그러나 그라디언트를 저장하는 dot grad 속성도 있습니다.

61
00:04:55,120 --> 00:05:00,800
지금 당장 당신은 x로 어떤 계산도 하지 않았기 때문에 dog grad가 없음을 알 수 있을 것입니다.

62
00:05:00,800 --> 00:05:05,030
당신은 pytorch에게 그라디언트를 취할 것을 말하지 않았습니다.

63
00:05:05,030 --> 00:05:09,680
x.grad 속성 안에는 아무것도 없습니다.

64
00:05:09,680 --> 00:05:13,750
하지만 손실을 정의할 때 어떤 일이 발생하는지 봅시다.

65
00:05:13,750 --> 00:05:16,160
여기에서 x와 y를 포함하는 몇 가지 계산을 하고 있습니다.

66
00:05:16,160 --> 00:05:18,880
우리는 그것들을 합산하여 스칼라 손실을 얻습니다.

67
00:05:18,880 --> 00:05:25,030
그 결과 텐서 손실에는 이 grad 함수 속성이 있습니다.

68
00:05:25,030 --> 00:05:33,680
그 이유는 기본적으로 grad가 true여야 하는 pytorch 텐서에서 모든 종류의 작업을 수행할 때마다입니다.

69
00:05:33,680 --> 00:05:41,360
pytorch는 여러분이 수행하는 모든 계산에 대한 자체 그래프를 암시적으로 구축합니다.

70
00:05:41,360 --> 00:05:45,910
각 텐서에 대해 해당 텐서에 도달하기 전에 어떤 함수가 적용되었는지 추적합니다.

71
00:05:45,910 --> 00:05:49,680
따라서 이 예제 grad 함수는 뒤로 0으로 합산됩니다.

72
00:05:49,680 --> 00:05:56,080
왜냐하면 당신이 손실에 도달한 방법은 당신이 그 전에 무언가에 대해 도트합을 호출했기 때문입니다.

73
00:05:56,080 --> 00:06:01,190
멋진 점은 실제로 이러한 grad 함수를 통해 다시 추적할 수 있다는 것입니다.

74
00:06:01,190 --> 00:06:09,190
pytorch가 내부 표현에 가지고 있는 계산 그래프를 보기 위해 처음부터 끝까지

75
00:06:09,190 --> 00:06:14,630
이것은 우리가 이전에 계산한 손실 함수의 계산 그래프입니다.

76
00:06:14,630 --> 00:06:20,470
그리고 우리는 이것을 뒤로가는 손실에서 인쇄하므로 첫 번째 것은 뒤로 합입니다.

77
00:06:20,470 --> 00:06:30,000
그리고 만약 우리가 그 grad 함수를 취해서 그 합이 pow backward zero에서 나온 것보다 앞의 것에서 왔다는 것을 의미하기 전에 무엇이 왔는지 알아낸다면

78
00:06:30,000 --> 00:06:33,190
우리는 그것을 얻기 위해 무언가를 제곱했기 때문에

79
00:06:33,190 --> 00:06:35,840
한 단계 뒤로 추적 추가

80
00:06:35,840 --> 00:06:37,600
그런 다음 한 단계 뒤로 추적

81
00:06:37,600 --> 00:06:40,630
당신은 우리가 두 가지 다른 것을 가지고 있음을 알 수 있습니다

82
00:06:40,630 --> 00:06:45,360
덧셈 연산의 덧셈 결과가 두 변수에서 나왔기 때문에

83
00:06:45,360 --> 00:06:50,560
첫 번째는 grad가 true여야 한다고 말한 일부 텐서 y였습니다.

84
00:06:50,560 --> 00:06:53,190
그래서 우리는 이 누적 대학원 작업을 가지고 있습니다.

85
00:06:53,190 --> 00:06:58,310
또 다른 것은 일종의 곱셈 연산이었습니다.

86
00:06:58,310 --> 00:07:00,400
그리고 다시 한 발짝 뒤로 물러나면

87
00:07:00,400 --> 00:07:03,280
우리는 이 다른 두 입력을 봅니다

88
00:07:03,280 --> 00:07:05,190
우리는 grad가 true와 같아야 한다고 지정한 곳에 x가 있습니다.

89
00:07:05,190 --> 00:07:14,240
기본적으로 그라디언트를 저장하는 것이 아닌 다른 값 2가 있습니다.

90
00:07:14,240 --> 00:07:18,630
자체 grad 기능이 없기 때문에

91
00:07:18,630 --> 00:07:22,560
따라서 이 계산 그래프에서 위의 각 노란색 노드에는 도트 그라드 속성이 있습니다.

92
00:07:22,560 --> 00:07:24,720
그리고 당신이 다시 소품을 할 때

93
00:07:24,720 --> 00:07:30,800
그리고 직접 속성이 손실에 대한 그라디언트를 저장할 것이라는 pytorch

94
00:07:30,800 --> 00:07:36,880
따라서 역전파를 수행하기 위해 계산 그래프의 특정 지점에서 일부 스칼라를 선택할 것입니다.

95
00:07:36,880 --> 00:07:38,560
그래서 여기서 우리는 손실을 선택할 것입니다

96
00:07:38,560 --> 00:07:41,520
그리고 우리는 lost.backward를 호출할 것입니다

97
00:07:41,520 --> 00:07:46,000
완료되면 이 모든 노란색 노드에 그라디언트가 채워집니다.

98
00:07:46,000 --> 00:07:53,680
dot grad 속성을 출력하면 이제 값이 있음을 알 수 있습니다.

99
00:07:53,680 --> 00:07:56,560
pytorch에서 약간 이상한 점은 그래디언트가 실제로 누적된다는 것입니다.

100
00:07:56,560 --> 00:08:02,800
따라서 동일한 작업을 다시 수행한 다음 마지막으로 다시 뒤로 호출하면

101
00:08:02,800 --> 00:08:06,560
이전 도트 그레이드를 덮어쓰는 것을 좋아하지 않으며 실제로 추가됩니다.

102
00:08:06,560 --> 00:08:10,560
그래서 당신은 두 배의 그라디언트를 얻게 될 것입니다

103
00:08:10,560 --> 00:08:14,080
이것이 때때로 유용할 수 있는 이유는 예를 들어

104
00:08:14,080 --> 00:08:16,560
여러 손실 함수가 있는 경우

105
00:08:16,560 --> 00:08:20,630
그리고 당신은 그 두 가지 모두에 대해 그라디언트를 취하고 싶습니다.

106
00:08:20,630 --> 00:08:25,030
동일한 매개변수 또는 이와 유사한 것을 사용하지 않더라도

107
00:08:25,030 --> 00:08:28,000
여전히 이러한 작업을 수행하고 dot를 뒤로 호출할 수 있습니다.

108
00:08:28,000 --> 00:08:31,280
그래서 이 경우 x에만 의존하는 손실 함수가 있습니다.

109
00:08:31,280 --> 00:08:36,710
그리고 그것을 거꾸로 호출하면 다른 손실 함수에서 가져온 이전 항목을 유지할 것입니다.

110
00:08:36,710 --> 00:08:43,030
그러나 이 두 번째 손실 함수 때문에 x dot grad가 여기에서 변경되었음을 알 수 있습니다.

111
00:08:43,030 --> 00:08:52,480
따라서 여러 손실 함수 또는 이와 유사한 것을 포함하는 더 복잡한 아키텍처로 작업하는 경우 유용할 수 있습니다.

112
00:08:52,480 --> 00:08:58,880
대부분의 경우 알아야 할 사항은 이러한 작업을 정의한다는 것입니다.

113
00:08:58,880 --> 00:09:11,600
여기에서 이 손실 함수를 정의한 다음 뒤로 손실되었다고 말하면 그라디언트가 자동으로 채워집니다.

114
00:09:11,600 --> 00:09:17,270
당신이 아마 꽤 자주 할 일은 그라디언트를 멈추고 시작하는 것입니다

115
00:09:17,270 --> 00:09:27,200
따라서 require right equals true를 지정하지 않으면 기본적으로 텐서는 추적되는 그라디언트가 없습니다.

116
00:09:27,200 --> 00:09:29,760
여기서 x는 그래디언트를 추적하지만 y는 추적하지 않습니다.

117
00:09:29,760 --> 00:09:37,510
따라서 손실을 계산하고 마지막 단계를 거꾸로 수행하면 x dot gradle이 채워지지만 y dot grad는 채워지지 않았음을 알 수 있습니다.

118
00:09:37,510 --> 00:09:40,320
텐서를 초기화한 후에는 언제든지 마음을 바꿀 수 있습니다.

119
00:09:40,320 --> 00:09:43,270
당신은 변경할 수 있습니다 grad는 사실이 필요합니다

120
00:09:43,270 --> 00:09:47,040
그리고 당신이 전화한 시점에서 그것이 사실인 한

121
00:09:47,040 --> 00:09:50,390
손실을 계산하고 법률 작업을 거꾸로 수행하는 곳

122
00:09:50,390 --> 00:09:52,320
그러면 그라디언트가 생깁니다.

123
00:09:52,320 --> 00:09:56,240
그러나 실제로 계산을 수행하기 전에 이 작업을 수행해야 합니다.

124
00:09:56,240 --> 00:10:04,800
pytorch는 각각의 grad 함수를 저장할 수 있어야 어디서 왔는지 기억할 수 있기 때문입니다.

125
00:10:04,800 --> 00:10:15,200
y.detach를 호출하여 그라디언트를 잘라낼 수도 있습니다. 일반적으로 그라디언트를 추적하려는 이 두 변수가 있다고 가정해 보겠습니다.

126
00:10:15,200 --> 00:10:21,360
하지만 나중에 어떤 이유로 인해 그라디언트를 추적하지 않는 계산을 하고 싶습니다.

127
00:10:21,360 --> 00:10:24,880
예를 들어 x와 y가 신경망의 가중치와 같다면

128
00:10:24,880 --> 00:10:28,390
훈련을 할 때 grad는 true와 같아야 합니다.

129
00:10:28,390 --> 00:10:35,040
그러나 실제로 평가할 때 그라디언트를 원하지 않을 수 있습니다.

130
00:10:35,040 --> 00:10:46,480
따라서 분리하지 않는 이유를 호출할 수 있으며 작업이 수행되지 않는 완전히 새로운 텐서를 반환할 것입니다. grad는 true가 필요합니다.

131
00:10:46,480 --> 00:10:50,000
따라서 원래 y는 실제로 여전히 동일하게 유지됩니다.

132
00:10:50,000 --> 00:10:52,390
하지만 지금 당신이 그 단계를 뒤로 부르면

133
00:10:52,390 --> 00:10:58,950
y detached에는 grad가 채워져 있지 않습니다.

134
00:10:58,950 --> 00:11:02,240
그래서 주의해야 할 몇 가지

135
00:11:02,240 --> 00:11:06,480
그런 다음 정확히 언제 이러한 것들을 사용할 것인지에 대해 이야기할 것입니다.

136
00:11:06,480 --> 00:11:14,070
따라서 첫 번째는 텐서가 grad가 true와 같아야 하는 경우 제자리 작업을 수행할 수 없다는 것입니다.

137
00:11:14,070 --> 00:11:21,920
y dot add underscore를 호출하거나 y의 단일 요소를 수정하는 것과 같이 y를 변경할 수 없습니다.

138
00:11:21,920 --> 00:11:28,950
그렇게하려고하면 오류 메시지가 나타납니다.

139
00:11:28,950 --> 00:11:34,480
나는 y를 변경하고 있으며 여기에 오류가 발생합니다.

140
00:11:34,480 --> 00:11:41,680
그 이유는 pytorch가 배경 목적으로만 작업을 추적할 수 있기 때문입니다.

141
00:11:41,680 --> 00:11:48,160
그것들을 곱하는 것을 더하는 것과 같은 이러한 순수한 기능의 관점에서 작성한다면

142
00:11:48,160 --> 00:11:51,040
텐서를 직접 수정할 수 없습니다.

143
00:11:51,040 --> 00:11:56,720
pytorch는 무언가가 변경되어 역전파가 엉망이 될 것이라는 사실을 깨닫지 못합니다.

144
00:11:56,720 --> 00:12:05,680
그리고 거의 같은 이유로 여전히 numpy에 대해 상당히 동일한 것을 요구하는 텐서를 변환할 수 없습니다.

145
00:12:05,680 --> 00:12:12,630
왜냐하면 우리는 실수로 numpy 배열을 수정하고 이 텐서에 대한 back prop 프로세스를 엉망으로 만들고 싶지 않기 때문에 동일한 메모리를 공유한다는 것을 기억하기 때문입니다.

146
00:12:12,630 --> 00:12:16,560
대신 실제로 해당 텐서를 numpy로 변환하려는 경우

147
00:12:16,560 --> 00:12:23,120
먼저 분리하기를 원하므로 텐서 y가 있습니다. y dot detach dot numpy라고 부를 수 있습니다.

148
00:12:23,120 --> 00:12:31,120
y dot detach가 grad를 필요로 하지 않는 새 텐서를 반환하더라도 이상한 문제가 있습니다.

149
00:12:31,120 --> 00:12:34,880
텐서는 여전히 y와 같은 메모리를 차지합니다.

150
00:12:34,880 --> 00:12:42,950
불행히도 여전히 실수로 이 y dot detach를 변경하거나 해당 numpy를 분리하지 않을 수 있습니다.

151
00:12:42,950 --> 00:12:49,040
그러면 y에도 영향을 미치게 되어 그라디언트가 엉망이 됩니다.

152
00:12:49,040 --> 00:12:59,920
따라서 grad가 필요한 pytorch 텐서를 numpy 배열이나 그라디언트가 없는 텐서로 true로 변환하려는 경우

153
00:12:59,920 --> 00:13:01,830
그리고 당신은 그것을 안전하게 돌연변이시킬 수 있기를 원합니다

154
00:13:01,830 --> 00:13:11,760
당신이해야 할 일은 그것을 분리 할뿐만 아니라 새로운 메모리에 텐서의 실제 사본을 제공하는 점 복제라고도합니다.

155
00:13:11,760 --> 00:13:20,800
그래서 이것은 지금 모든 종류의 추상적 인 것입니다. 왜 이 모든 것이 필요한지 궁금해 할 것입니다.

156
00:13:20,800 --> 00:13:26,950
numpy 분리 요구 사항 및 이와 유사한 것으로 변환

157
00:13:26,950 --> 00:13:32,390
그리고 적어도 rl과 관련하여

158
00:13:32,390 --> 00:13:34,880
일반적으로 결국 일어나는 일은

159
00:13:34,880 --> 00:13:39,600
때로는 numpy 배열로 작업하고 때로는 텐서로 작업합니다.

160
00:13:39,600 --> 00:13:46,390
예를 들어 에이전트를 교육하려는 환경이 있다고 가정해 보겠습니다.

161
00:13:46,390 --> 00:13:53,360
그런 다음 일련의 pytorch 텐서처럼 표현되는 모델이 있습니다.

162
00:13:53,360 --> 00:14:00,390
일반적으로 환경에 대한 시뮬레이터는 파이 토치 텐서가 아닌 numpy 배열로 작업할 것입니다.

163
00:14:00,390 --> 00:14:05,270
시뮬레이터 코드를 별도의 유형으로 유지하는 것이 좋습니다.

164
00:14:05,270 --> 00:14:12,070
에이전트를 훈련시키는 데 사용하는 딥 러닝 프레임워크에 의존해서는 안 됩니다.

165
00:14:12,070 --> 00:14:15,270
그래서 그것은 미터가 numpy 배열과 함께 작동할 것입니다.

166
00:14:15,270 --> 00:14:24,630
이 시뮬레이션된 환경에서 numpy 배열로 표시되는 유사한 상태로 가득 찬 데이터 세트가 있는 경우

167
00:14:24,630 --> 00:14:27,600
rl에 대한 학습을 시작하고 싶을 것이다.

168
00:14:27,600 --> 00:14:34,000
당신이 할 일은 그 numpy 배열에서 pytorch 텐서로 변환하는 것입니다

169
00:14:34,000 --> 00:14:39,600
그리고 그 파이를 텐서에 사용하면 모델에 대한 훈련을 할 수 있습니다.

170
00:14:39,600 --> 00:14:43,120
그리고 실제로 예측을 할 때

171
00:14:43,120 --> 00:14:47,040
numpy 배열인 환경에서 일종의 상태를 얻을 수 있습니다.

172
00:14:47,040 --> 00:14:50,800
그래서 당신은 그것을 pytorch 텐서로 변환하고 싶을 것입니다

173
00:14:50,800 --> 00:14:55,760
해당 텐서를 사용하여 모델을 실행하고 예측된 조치를 취하십시오.

174
00:14:55,760 --> 00:15:02,160
그러나 아마도 해당 작업을 분리하고 다시 numpy 배열로 변환하고 싶을 것입니다.

175
00:15:02,160 --> 00:15:05,760
그것은 단지 일반적으로 좋은 컨벤션입니다

176
00:15:05,760 --> 00:15:15,440
정책의 출력이 실제로 그라디언트를 추적해야 하거나 추가 pytorch 작업을 수행해야 하는 것이 아니기 때문에

177
00:15:15,440 --> 00:15:26,390
따라서 훈련 또는 추론과 관련된 작업을 수행하는 중간 계층에만 pytorch를 사용하는 것이 좋습니다.

178
00:15:26,390 --> 00:15:31,190
하지만 numpy 배열을 사용하여 실제로 환경의 상태를 나타냅니다.

179
00:15:31,190 --> 00:15:33,750
그리고 당신이 취하기로 선택한 행동

180
00:15:33,750 --> 00:15:41,830
이것은 이러한 변환 함수로 작업하거나 분리와 같은 것을 사용해야 하는 경우의 예입니다.

