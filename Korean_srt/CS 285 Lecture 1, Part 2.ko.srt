1
00:00:01,199 --> 00:00:06,580
그렇다면 왜 우리는 심층 강화 학습에 관심을 가져야 할까요?

2
00:00:06,720 --> 00:00:09,220
특히 이 수업의 제목에 Deep이 있는 만큼, 
이에 대해 조금 이야기합시다.

3
00:00:10,000 --> 00:00:12,900
은그리고 이 주제에 대해 강의하기 앞서, 
좀 더 큰 범위에서 질문을 해봅시다.

4
00:00:13,000 --> 00:00:18,100
그리고 이 질문은 우리가 첫 번째 강의에서도 몇 번 언급했던 것입니다.

5
00:00:18,240 --> 00:00:24,320
지능형 기계는 어떻게 만들까요?

6
00:00:21,840 --> 00:00:26,880
이 말은 앞서 언급했던 말 그대로

7
00:00:24,880 --> 00:00:32,719
우리가 만화에서 볼 수 있거나,

8
00:00:28,960 --> 00:00:34,320
로봇 집사, 의료목적의 로봇 도우미,

9
00:00:32,719 --> 00:00:36,880


10
00:00:34,320 --> 00:00:38,079
혹은 공상 과학 영화에 나오는 우주선을 조종하는 로봇 같은 지능형 기계를 의미합니다.

11
00:00:36,880 --> 00:00:39,760


12
00:00:38,079 --> 00:00:41,120
아니면 좀 더 장난꾸러기 성향이 있다면

13
00:00:39,760 --> 00:00:44,559


14
00:00:41,120 --> 00:00:46,079
사악한 로봇 악당도 될 수 있겠네요.

15
00:00:44,559 --> 00:00:48,079
지능형 기계는 여러 상황에 적응할 수 있어야 합니다.

16
00:00:46,079 --> 00:00:49,760
지능형 기계들은 세계의 복잡성과 불확실성에 대해서

17
00:00:48,079 --> 00:00:52,079
유연하게 현실 세계의 복잡성과 예측 불가능성을 
유연하게 처리할 수 있어야 합니다.

18
00:00:49,760 --> 00:00:54,000


19
00:00:52,079 --> 00:00:56,079
예를 들어, 자율 주행 유조선을 만들고 싶다면

20
00:00:54,000 --> 00:00:57,440


21
00:00:56,079 --> 00:00:59,920
사실, 이것은 현재 아마 그리 어려운 것이 아닙니다.

22
00:00:57,440 --> 00:01:00,559
인간에게 어떻게 지구의 반대편에 떨어져 있는 곳으로

23
00:00:59,920 --> 00:01:02,320


24
00:01:00,559 --> 00:01:04,239
바다를 항해하여 도착할 것인지 알아내는 것은 어려운 일이지만,

25
00:01:02,320 --> 00:01:06,640


26
00:01:04,239 --> 00:01:07,760
GPS와 모션 플래닝의 조합으로

27
00:01:06,640 --> 00:01:09,360
합리적으로 이 문제를 잘 해결할 수 있습니다.

28
00:01:07,760 --> 00:01:11,439


29
00:01:09,360 --> 00:01:12,799
그러나 대부분의 유조선에는 여전히 사람이 타고 있습니다.

30
00:01:11,439 --> 00:01:14,479


31
00:01:12,799 --> 00:01:15,680
왜 그럴까요?

32
00:01:14,479 --> 00:01:17,040
왜냐하면, 뭔가 잘못된 상황이 엔진룸에서 발생했을 때,

33
00:01:15,680 --> 00:01:18,320


34
00:01:17,040 --> 00:01:20,159
우리는 그곳에 내려가 문제를 고칠 사람이 필요합니다.

35
00:01:18,320 --> 00:01:21,280


36
00:01:20,159 --> 00:01:23,040
유조선을 항해하는 것은 비교적 어렵지 않은

37
00:01:21,280 --> 00:01:25,200
인공지능 문제 이지만,

38
00:01:23,040 --> 00:01:27,520


39
00:01:25,200 --> 00:01:29,280
현재 기술로 잘못되었을 때 수정하는 것은 매우 어렵습니다.

40
00:01:27,520 --> 00:01:31,680


41
00:01:32,159 --> 00:01:36,360
이 어려움은 현실 세계가 구조화되지 않고 예측할 수 없기 때문입니다.

42
00:01:33,520 --> 00:01:36,479


43
00:01:35,360 --> 00:01:36,400


44
00:01:36,479 --> 00:01:40,079
그리고 현실세계의 구조화되지 않고,
예측 불가능한 특성을 처리할 수 있으면서,

45
00:01:38,400 --> 00:01:41,759


46
00:01:40,079 --> 00:01:44,140
우리가 마음대로 사용할 수 있는 정말 강력한 기술이 바로 
딥 러닝입니다.

47
00:01:41,759 --> 00:01:44,180


48
00:01:44,240 --> 00:01:49,119
딥 러닝에서는 입력과 출력을 매핑하기 위해,

49
00:01:47,280 --> 00:01:51,840
심층 신경망과 같이 과도하게 매개변수화된 매우 큰 모델을 훈련시킵니다.

50
00:01:49,119 --> 00:01:51,979


51
00:01:52,000 --> 00:01:55,119
예를 들어, 이미지에서 개체를 인식하려는 경우

52
00:01:54,079 --> 00:01:56,799


53
00:01:55,119 --> 00:01:58,479
많은 라벨링된 이미지를 수집한 다음

54
00:01:56,799 --> 00:02:00,320


55
00:01:58,479 --> 00:02:01,840
일반적으로 지도 학습 방법을

56
00:02:00,320 --> 00:02:04,560
사용하여 출력에서 입력을 예측합니다.

57
00:02:02,719 --> 00:02:06,240
하지만 딥러닝은 본적으로

58
00:02:04,560 --> 00:02:08,239
에알고리즘의 선택보다는 과도하게 매개변수화된 대규모 모델의 선택에 따릅니다.

59
00:02:06,880 --> 00:02:10,319


60
00:02:08,239 --> 00:02:11,440
우리는 딥 러닝 방법이 이미지 분류부터 텍스트 번역,

61
00:02:10,319 --> 00:02:15,360
심지어 이미지에서 직접 번역,

62
00:02:12,720 --> 00:02:17,540
사람의 음성 인식까지 이르기까지 
다양한 작업에서 성공하는 것을 보았습니다.

63
00:02:15,360 --> 00:02:18,280


64
00:02:18,480 --> 00:02:21,840
그리고 이것들은 오픈 월드 세팅입니다.

65
00:02:20,480 --> 00:02:23,040
다시말해, 전에 본 적이 없는 모든 종류의 특수한 경우와

66
00:02:21,840 --> 00:02:24,720
비정상적인 상황이 발생할 수 있는 것들을

67
00:02:23,040 --> 00:02:28,080


68
00:02:25,599 --> 00:02:31,599
효과적으로 일반화시킬 수 있는 모델이 필요하다는 말입니다.

69
00:02:28,080 --> 00:02:31,299


70
00:02:31,920 --> 00:02:34,800
강화 학습은 제가 이전에 언급한 것처럼

71
00:02:33,200 --> 00:02:36,480
가행동에 대한 형식주의를 제공합니다.

72
00:02:34,800 --> 00:02:38,239
수학을 제공하기 전에

73
00:02:36,480 --> 00:02:41,680
순차적 의사 결정에 대한 사고 방식.

74
00:02:39,680 --> 00:02:44,239
강화 학습에서 에이전트는 세계와

75
00:02:41,680 --> 00:02:46,400
상호 작용하고 관찰 및 보상을 얻습니다.

76
00:02:44,239 --> 00:02:48,000
이러한 종류의 방법이 조합되어 사용되었습니다.

77
00:02:46,400 --> 00:02:51,120


78
00:02:48,000 --> 00:02:51,440
다양한 심층 신경망으로

79
00:02:51,120 --> 00:02:53,280


80
00:02:51,440 --> 00:02:54,560
유연하게 처리해야 하는 애플리케이션

81
00:02:53,280 --> 00:02:56,800


82
00:02:54,560 --> 00:02:58,640
이상하고 예측할 수 없는 상황.

83
00:02:56,800 --> 00:03:00,159
예를 들어, 강화의 조합의 초기 성공 중 하나

84
00:02:58,640 --> 00:03:02,000


85
00:03:00,159 --> 00:03:03,120
학습과 신경망은 노는 법을 배우고 있습니다.

86
00:03:02,000 --> 00:03:06,080


87
00:03:03,120 --> 00:03:07,519
주사위 놀이의 보드 게임.

88
00:03:06,080 --> 00:03:08,959
이것은 주사위 놀이를 배운 td

89
00:03:07,519 --> 00:03:10,800
gammon이라는 시스템입니다.

90
00:03:08,959 --> 00:03:11,760
전문가 수준의 인간.

91
00:03:10,800 --> 00:03:13,760
챔피언 인간 플레이어를 이길 수준은 아니지만 매우

92
00:03:11,760 --> 00:03:15,680


93
00:03:13,760 --> 00:03:18,080
매우 전문적인 수준에서.

94
00:03:15,680 --> 00:03:21,360
바둑 2016에서 인간 챔피언을 물리친 알파고의 기술

95
00:03:18,080 --> 00:03:23,440


96
00:03:21,360 --> 00:03:26,000
여러 면에서 90년대의 td

97
00:03:23,440 --> 00:03:27,360
gammon과 많은 공통점이 있었습니다.

98
00:03:26,000 --> 00:03:28,720
강화 학습 알고리즘을 의미하는 심층 강화 학습 방법

99
00:03:27,360 --> 00:03:31,280


100
00:03:29,360 --> 00:03:33,040
심층 신경망을 사용하는 작업은

101
00:03:31,280 --> 00:03:34,879
다음과 같은 작업에 사용되었습니다.

102
00:03:33,040 --> 00:03:36,080
로봇 조작 기술에 로봇 운동

103
00:03:34,879 --> 00:03:39,280


104
00:03:36,080 --> 00:03:42,319
비디오 게임 등.

105
00:03:39,280 --> 00:03:44,000
그렇다면 deep RL은 정확히 무엇입니까?

106
00:03:42,319 --> 00:03:46,319
그리고 왜 우리가 그것에 관심을 가져야 합니까?

107
00:03:44,000 --> 00:03:47,920
음, 깊은 RL의 중요성을 이해하려면

108
00:03:46,319 --> 00:03:49,040


109
00:03:47,920 --> 00:03:51,519
강화 학습 방법

110
00:03:49,040 --> 00:03:52,799
다른 도메인의 예부터 시작하겠습니다.

111
00:03:51,519 --> 00:03:54,400


112
00:03:52,799 --> 00:03:56,959
왜 그것이 딥 뉴럴인지 알아보기 위해 컴퓨터 비전의 예

113
00:03:54,400 --> 00:03:57,599


114
00:03:56,959 --> 00:03:59,200
네트워크는 이러한 변화에 영향을 미칩니다.

115
00:03:57,599 --> 00:04:01,920


116
00:03:59,200 --> 00:04:04,000
머신 러닝 시스템의 기능.

117
00:04:01,920 --> 00:04:05,040
그래서 우리가 시간을 되돌린다면 아마도

118
00:04:04,000 --> 00:04:06,159
15년에서 20년 사이에 컴퓨터

119
00:04:05,040 --> 00:04:07,680
비전이 어땠는지 살펴보세요.

120
00:04:06,159 --> 00:04:08,720
일반적으로 우리는 이와 같은 것을 볼 것입니다.

121
00:04:07,680 --> 00:04:10,720


122
00:04:08,720 --> 00:04:12,640
이미지의 픽셀로 시작하고

123
00:04:10,720 --> 00:04:14,159
그런 다음 손으로 디자인한 일부를 추출합니다.

124
00:04:12,640 --> 00:04:16,079
낮은 수준의 시각적 기능

125
00:04:14,159 --> 00:04:18,000
예를 들어 방향이 지정된

126
00:04:16,079 --> 00:04:20,079
그라디언트의 히스토그램과 같은 픽셀.

127
00:04:18,000 --> 00:04:22,320
그런 다음 일부 중간 수준 기능을 추출할 수 있습니다.

128
00:04:20,079 --> 00:04:25,120
예를 들어 변형 가능한 부품 모델과 같이

129
00:04:23,280 --> 00:04:26,960
그런 다음 중간 수준 기능 위에

130
00:04:25,120 --> 00:04:28,000
당신은 간단한 선형 분류기를 훈련시킬 것입니다

131
00:04:26,960 --> 00:04:29,600


132
00:04:28,000 --> 00:04:30,880
당신이 원하는 것을 실제로 분류하는 서포트 벡터 머신처럼.

133
00:04:29,600 --> 00:04:35,280


134
00:04:32,639 --> 00:04:37,600
이제 딥 러닝으로 심층 신경망은

135
00:04:35,840 --> 00:04:39,520
거의 동일한 기능을 수행합니다.

136
00:04:37,600 --> 00:04:40,639
내부적으로는 중간 수준의 기능을 가지고 있으며

137
00:04:39,520 --> 00:04:42,639
저수준 기능과 분류기의 차이점은

138
00:04:40,639 --> 00:04:44,000


139
00:04:42,639 --> 00:04:46,800
이제 손으로 디자인할 필요가 없습니다.

140
00:04:44,479 --> 00:04:48,560
그들은 실제로

141
00:04:46,800 --> 00:04:50,160
심층 신경망.

142
00:04:48,560 --> 00:04:52,000
이것은 우리가 이러한 모든 것을 설계하는 데 많은

143
00:04:50,160 --> 00:04:52,960
인간의 노력을 절약한다는 것을 의미할 뿐만 아니라

144
00:04:52,000 --> 00:04:54,880
특징.

145
00:04:52,960 --> 00:04:56,320
그러나 그것은 또한 기능이 그들이 수행하는

146
00:04:54,880 --> 00:04:57,600
작업에 최적으로 적용된다는 것을 의미합니다.

147
00:04:56,320 --> 00:04:58,960
실제로 해결해야 합니다.

148
00:04:57,600 --> 00:05:00,800
따라서 일반적인 히스토그램이나

149
00:04:58,960 --> 00:05:01,919
성분 기능을 얻을 수 없습니다.

150
00:05:00,800 --> 00:05:06,320
재규어에서 호랑이를 분류하기

151
00:05:01,919 --> 00:05:07,680
위한 올바른 기능을 얻으십시오.

152
00:05:06,320 --> 00:05:09,520
이제 이 강의가 강화 학습 설정에

153
00:05:07,680 --> 00:05:10,120
어떻게 매핑되는지 생각해 보겠습니다.

154
00:05:10,160 --> 00:05:13,379
주사위 놀이에 대해 생각해 봅시다.

155
00:05:13,520 --> 00:05:16,720
표준 강화 학습 방법을 사용하려면

156
00:05:14,479 --> 00:05:18,160


157
00:05:16,720 --> 00:05:19,759
어떻게든 주사위 놀이 게임에서 기능을 추출해야 합니다.

158
00:05:18,160 --> 00:05:21,840


159
00:05:19,759 --> 00:05:23,440
어떤 종류의 기능을 사용합니까?

160
00:05:21,840 --> 00:05:24,720
글쎄, 아마도 당신이 주사위 놀이를하는

161
00:05:23,440 --> 00:05:26,160
사람이라면 다음이 있다는 것을 알고있을 것입니다.

162
00:05:24,720 --> 00:05:27,759
게임에서 중요한 몇 가지 나는 전문

163
00:05:26,160 --> 00:05:29,039
주사위 놀이 플레이어가 아니므로

164
00:05:27,759 --> 00:05:30,320
그것들이 무엇인지 모르지만 아마도

165
00:05:29,039 --> 00:05:30,800
그것들이 무엇인지 알고 있을 것입니다.

166
00:05:30,320 --> 00:05:33,360
당신은 그것들을 기록할 수 있습니다.

167
00:05:30,800 --> 00:05:33,620


168
00:05:32,460 --> 00:05:34,700
하지만 중요하다고 생각하는 기능만

169
00:05:34,320 --> 00:05:36,800
있는 것만으로는 충분하지 않습니다.

170
00:05:35,600 --> 00:05:37,440
게임의 경우 기능도 있어야 합니다.

171
00:05:36,800 --> 00:05:40,320


172
00:05:37,440 --> 00:05:41,840
정책 가치 기능 및 기타 객체를

173
00:05:40,320 --> 00:05:43,360
나타내는 데 사용할 수 있습니다.

174
00:05:41,840 --> 00:05:44,400
몇 가지 간단한 방법으로 강화 학습과 관련이 있습니다.

175
00:05:43,360 --> 00:05:47,440


176
00:05:44,400 --> 00:05:48,800
표 또는 선형 표현처럼.

177
00:05:47,440 --> 00:05:50,880
그리고 그것은 훨씬 더 어려운 디자인입니다.

178
00:05:48,800 --> 00:05:53,360
왜냐하면 지금 당신은 단지 디자인 뿐만 아니라

179
00:05:50,880 --> 00:05:55,520
전문가이자 주사위 놀이 뿐만 아니라

180
00:05:53,360 --> 00:05:56,880
강화 학습의 전문가이기도 합니다.

181
00:05:55,520 --> 00:05:59,039
그리고 어떤 기능이 좋은지에 대한 많은 직관이 필요합니다.

182
00:05:56,880 --> 00:06:00,560


183
00:05:59,039 --> 00:06:02,080
이것은 실제로 매우 어려운 것으로 밝혀졌고 오랫동안

184
00:06:00,560 --> 00:06:03,039


185
00:06:02,080 --> 00:06:04,800
강화 학습 방법을 적용하기가 매우 어렵습니다.

186
00:06:03,039 --> 00:06:07,680


187
00:06:04,800 --> 00:06:09,360
복잡한 문제에.

188
00:06:07,680 --> 00:06:11,600
딥 러닝은 강화 학습에 했던

189
00:06:09,360 --> 00:06:13,360
것과 동일한 공식을 적용합니다.

190
00:06:11,600 --> 00:06:14,720
수동 기능을 대체하는 컴퓨터 임무 문제에

191
00:06:13,360 --> 00:06:15,520


192
00:06:14,720 --> 00:06:17,199
자동으로 학습된 기능으로 추출

193
00:06:15,520 --> 00:06:18,880


194
00:06:17,199 --> 00:06:21,440
심층 신경망으로 표현하고 종단 간 훈련.

195
00:06:18,880 --> 00:06:23,199


196
00:06:21,440 --> 00:06:24,479
그러나 일반적으로 광범위한 문제에 대한 강화 학습 설정에서

197
00:06:23,199 --> 00:06:26,160


198
00:06:24,479 --> 00:06:27,360
기능 설계에 대한 직관을 처리하려는

199
00:06:26,160 --> 00:06:29,039


200
00:06:27,360 --> 00:06:33,280
컴퓨터 비전보다 훨씬 약하며

201
00:06:30,960 --> 00:06:34,319
이러한 이유로 심층 강화 학습 방법은

202
00:06:33,280 --> 00:06:35,919
강화 학습 알고리즘의 기능에 대한 변형 효과.

203
00:06:34,319 --> 00:06:38,319


204
00:06:39,200 --> 00:06:46,400
그렇다면 순차 의사 결정에서
종단 간 학습은 무엇을 의미합니까?

205
00:06:43,600 --> 00:06:49,199
음, 먼저 의도된 학습이 없다는 것이

206
00:06:46,400 --> 00:06:50,319
무엇을 의미하는지 설명하겠습니다.

207
00:06:49,199 --> 00:06:51,680
의도한 학습이 없을 때 처리해야 함을 의미합니다.

208
00:06:50,319 --> 00:06:53,039


209
00:06:51,680 --> 00:06:54,880
문제의 인식 부분과 문제의 제어 부분을 별도로 분리합니다.

210
00:06:53,039 --> 00:06:57,440


211
00:06:54,880 --> 00:06:58,560
그래서 아마도 당신은 당신이 보고 있는 것을

212
00:06:57,440 --> 00:07:00,560
알아내는 하나의 시스템을 가지고 있을 것입니다.

213
00:06:58,560 --> 00:07:02,720
이미지 당신은 호랑이, 재규어

214
00:07:00,560 --> 00:07:04,400
또는 무해한 것을 보고 있습니까?

215
00:07:02,720 --> 00:07:06,160
실제로 무엇을 기반으로 할 것인지 결정하는

216
00:07:04,400 --> 00:07:09,360
또 다른 구성 요소로 연결되는 파이프라인

217
00:07:06,160 --> 00:07:09,360
그 지각적 결과에 대해.

218
00:07:09,520 --> 00:07:12,639
그리고 당신은 당신의 지각

219
00:07:11,360 --> 00:07:13,440
체계를 좋은 지각 체계로 훈련시키고

220
00:07:12,639 --> 00:07:14,800
보고 있는 것을 정확하게 인식하고

221
00:07:13,440 --> 00:07:16,479


222
00:07:14,800 --> 00:07:18,400
제어 시스템이 올바른 조치를 취하기 위한

223
00:07:16,479 --> 00:07:19,759
좋은 제어 시스템이 되도록 훈련하십시오.

224
00:07:18,400 --> 00:07:21,680
그러나 지각 시스템은 별도로 훈련되기 때문에

225
00:07:19,759 --> 00:07:22,560


226
00:07:21,680 --> 00:07:24,800
그것이 알지 못하는 행동 체계의 요구

227
00:07:22,560 --> 00:07:26,000


228
00:07:24,800 --> 00:07:27,120
어떤 종류의 탐지가 중요한지,

229
00:07:26,000 --> 00:07:29,599
어떤 종류가 중요하지 않은지,

230
00:07:27,120 --> 00:07:30,960
어떤 종류의 실수가 비용이 많이 들고

231
00:07:29,599 --> 00:07:32,560
어떤 종류의 실수가 비용이 덜 듭니다.

232
00:07:30,960 --> 00:07:35,680
그리고 그것은 우리가 호랑이에게서

233
00:07:32,560 --> 00:07:35,680
도망쳐야 하는 큰 일입니다.

234
00:07:35,759 --> 00:07:38,720
강렬한 시스템은 감각 운동 루프를 닫지만 실제로는

235
00:07:37,680 --> 00:07:40,240


236
00:07:38,720 --> 00:07:42,400
전체 시스템 종단 간

237
00:07:40,240 --> 00:07:43,759
지각과 통제를 동시에 수행

238
00:07:42,400 --> 00:07:46,319


239
00:07:43,759 --> 00:07:48,000
작업의 최종 수행에 의해 직접 정보를 받는 행동 특징.

240
00:07:46,319 --> 00:07:51,440


241
00:07:50,000 --> 00:07:53,039
다음은 몇 가지 예시적인 애플리케이션

242
00:07:51,440 --> 00:07:54,240
시나리오에서 의미하는 바입니다.

243
00:07:53,039 --> 00:07:56,160
로봇 제어 기존 로봇 파이프라인은

244
00:07:54,240 --> 00:07:57,440


245
00:07:56,160 --> 00:07:59,680
를 추정하는 관찰을 수행하는 단계로 구성됩니다.

246
00:07:57,440 --> 00:08:01,759


247
00:07:59,680 --> 00:08:02,960
약간의 모델링 및 예측을 수행하는 객체의 위치와 같은 상태

248
00:08:01,759 --> 00:08:04,720


249
00:08:02,960 --> 00:08:06,000
해당 객체가 미래에 어떻게 동작할지 파악

250
00:08:04,720 --> 00:08:05,960


251
00:08:06,000 --> 00:08:08,600
해당 모델링 및 예측을 기반으로 일부 계획 수행

252
00:08:08,939 --> 00:08:11,960
그 위에 몇 가지 낮은 수준의 제어를 수행하는 등

253
00:08:12,100 --> 00:08:15,979
중요한 것은 이 프로세스의 각 단계에서
약간의 오류가 발생할 수 있다는 것입니다.

254
00:08:16,100 --> 00:08:20,120
물체가 어디에 있는지 감지하는 데 실수를 할 수 있습니다.

255
00:08:16,479 --> 00:08:20,879


256
00:08:18,720 --> 00:08:22,400
그 시점에서 당신이 구성하는 계획은

257
00:08:20,879 --> 00:08:23,680


258
00:08:22,400 --> 00:08:25,360
그것은 잘못된 전제에 기반을

259
00:08:23,680 --> 00:08:26,960
두고 있기 때문에 현실 세계입니다.

260
00:08:25,360 --> 00:08:28,560
인텐트 접근 방식은 이 문제를 극복할 수 있습니다.

261
00:08:26,960 --> 00:08:30,479


262
00:08:28,560 --> 00:08:31,759
이 파이프라인의 각 단계는

263
00:08:30,479 --> 00:08:33,120
다음 요구 사항에 따라 알려집니다.

264
00:08:31,759 --> 00:08:33,100
라인 아래로 단계.

265
00:08:33,120 --> 00:08:34,740
따라서 로봇 제어에 대한 심층 강화

266
00:08:34,800 --> 00:08:37,539
학습 접근 방식을 상상할 수 있습니다.

267
00:08:37,599 --> 00:08:42,719
지각과 행동을 모두 수행하는

268
00:08:40,640 --> 00:08:44,320
컨볼루션 심층 신경망이 있는 곳입니다.

269
00:08:42,719 --> 00:08:46,080
따라서 로봇 카메라의 이미지는 이

270
00:08:44,320 --> 00:08:49,279
네트워크의 맨 아래에 맞춰집니다.

271
00:08:46,080 --> 00:08:51,200
끝에서 나오는 출력은 로봇의 액츄에이터에 공급됩니다.

272
00:08:49,279 --> 00:08:53,680


273
00:08:51,200 --> 00:08:54,640
이러한 종류의 감각 운동 루프는 다음을 나타냅니다.

274
00:08:53,680 --> 00:08:56,320


275
00:08:54,640 --> 00:08:57,920
약간의 시각적 구성 요소가 있는

276
00:08:56,320 --> 00:08:59,279
이 로봇을 위한 두뇌의 작은 축소판

277
00:08:57,920 --> 00:09:00,880
작은 행동 요소.

278
00:08:59,279 --> 00:09:02,800
그러나 그들 모두는 엔드 투 엔드 교육을 받았습니다.

279
00:09:00,880 --> 00:09:04,160
작업의 최종 수행을 위해.

280
00:09:02,800 --> 00:09:06,320
따라서 매우 긴장된 비유를 사용하기

281
00:09:04,160 --> 00:09:08,000
위해 컨볼루션 레이어를 생각할 수 있습니다.

282
00:09:06,320 --> 00:09:10,240
일종의 고도로 전문화된 시각 피질과 완전히 연결된

283
00:09:08,000 --> 00:09:11,839


284
00:09:10,240 --> 00:09:12,959
층은 아주 작은 고도로 전문화된 운동 피질입니다.

285
00:09:11,839 --> 00:09:14,720


286
00:09:12,959 --> 00:09:16,080
하지만 그들은 모두 훈련을 받았고 끝내야 하기 때문에 결국

287
00:09:14,720 --> 00:09:17,600


288
00:09:16,080 --> 00:09:18,880
그들의 능력 내에서 작업에 가장 적합한 것은 무엇이든

289
00:09:17,600 --> 00:09:20,640


290
00:09:18,880 --> 00:09:21,839
대표 능력.

291
00:09:20,640 --> 00:09:24,000
따라서 로봇은 이 작업을 수행하는

292
00:09:21,839 --> 00:09:26,399
경험을 통해 학습할 수 있습니다.

293
00:09:24,000 --> 00:09:27,200
그리고 그것을 사용하여 이 네트워크의

294
00:09:26,399 --> 00:09:29,279
모든 가중치를 끝에서 끝까지 훈련합니다.

295
00:09:30,240 --> 00:09:34,880
강화 문제의 이러한 어 예제

296
00:09:32,640 --> 00:09:37,519
응용 프로그램에 대해 생각해 보면,

297
00:09:34,880 --> 00:09:39,440
심층 신경망 표현과 결합하면

298
00:09:37,519 --> 00:09:42,000


299
00:09:39,440 --> 00:09:42,959
강화 학습 시스템은 실제로

300
00:09:42,000 --> 00:09:44,959


301
00:09:42,959 --> 00:09:47,040
어떤 의미에서 AI 문제의 전체.

302
00:09:44,959 --> 00:09:48,000
지도 학습 시스템에는 다음이 필요합니다.

303
00:09:47,040 --> 00:09:50,160


304
00:09:48,000 --> 00:09:51,120
입력 및 출력 감독.

305
00:09:50,160 --> 00:09:53,600
강화 학습 시스템은 의존하지

306
00:09:51,120 --> 00:09:55,360
않고 최적의 행동을 목표로 합니다.

307
00:09:53,600 --> 00:09:57,920
보상 피드백에 의존하기 위해 그러한 감독에 대해.

308
00:09:55,360 --> 00:09:59,120


309
00:09:57,920 --> 00:10:01,200
그리고 심층 모델은 강화 학습 알고리즘이

310
00:09:59,120 --> 00:10:02,720


311
00:10:01,200 --> 00:10:03,760
복잡한 문제를 끝까지

312
00:10:02,720 --> 00:10:05,680
강화 학습은 수학적 형식을 제공합니다.

313
00:10:03,760 --> 00:10:06,959


314
00:10:05,680 --> 00:10:08,480
심층 모델이 제공하는 동안 알고리즘 기반

315
00:10:06,959 --> 00:10:10,160


316
00:10:08,480 --> 00:10:11,360
이러한 알고리즘 기반을 허용하는 표현

317
00:10:10,160 --> 00:10:15,120


318
00:10:11,360 --> 00:10:15,120
실제 시스템으로 확장할 수 있습니다.

319
00:10:16,079 --> 00:10:19,000
그렇다면 왜 지금 이러한 질문을 연구해야 합니까?

320
00:10:19,200 --> 00:10:22,399
글쎄요, 지난 10년 동안 많은 발전이 있었습니다.

321
00:10:20,720 --> 00:10:23,839


322
00:10:22,399 --> 00:10:25,360
이것은 심층 강화 학습을

323
00:10:23,839 --> 00:10:26,480
연구하기에 정말 흥미로운 시간입니다.

324
00:10:25,360 --> 00:10:28,720
첫째, 딥러닝 자체에서 엄청난 발전이 있었습니다.

325
00:10:26,480 --> 00:10:31,440


326
00:10:28,720 --> 00:10:33,360
심층 신경망 표현을 구축하는 방법.

327
00:10:30,640 --> 00:10:33,359


328
00:10:33,360 --> 00:10:36,399
강화 학습 알고리즘에도 많은 발전이 있었습니다.

329
00:10:34,959 --> 00:10:37,839


330
00:10:36,399 --> 00:10:38,060
이러한 딥 러닝 표현을 사용하여

331
00:10:37,839 --> 00:10:40,780
이러한 방법을 확장할 수 있습니다.

332
00:10:40,880 --> 00:10:43,920
마지막으로 컴퓨팅 능력의 발전

333
00:10:43,120 --> 00:10:45,279


334
00:10:43,920 --> 00:10:49,200
이 두 요소를 결합하는 것이 그 어느

335
00:10:45,279 --> 00:10:49,200
때보다 실용적으로 만들어졌습니다.

336
00:10:49,360 --> 00:10:52,959
딥 강화 학습의 기본 기반은

337
00:10:51,279 --> 00:10:54,160


338
00:10:52,959 --> 00:10:55,760
새로운 것을 의미합니다.

339
00:10:54,160 --> 00:10:57,519
예를 들어 제어를 위한 신경망에 대한 교과서가 있습니다.

340
00:10:55,760 --> 00:10:58,880


341
00:10:57,519 --> 00:11:00,720
수십 년 전으로 돌아가

342
00:10:58,880 --> 00:11:03,440
1980년대.

343
00:11:00,720 --> 00:11:04,560
그리고 90년대의 작업에서도

344
00:11:03,440 --> 00:11:07,040
실제로 많은 논의가 이루어졌습니다.

345
00:11:04,560 --> 00:11:08,560
예를 들어 오늘날 최첨단 연구의 일부인 성분

346
00:11:07,040 --> 00:11:09,680


347
00:11:08,560 --> 00:11:12,560
1993년의 박사 학위 논문은

348
00:11:09,680 --> 00:11:13,920
현대에 필요한 몇 가지를 말합니다.

349
00:11:12,560 --> 00:11:15,519
심층 강화 학습 연구원은 다음과 같이 매우 친숙합니다.

350
00:11:13,920 --> 00:11:17,519


351
00:11:15,519 --> 00:11:18,720
강화 학습은 인공 신경과 자연스럽게 통합될 수 있습니다.

352
00:11:17,519 --> 00:11:19,279


353
00:11:18,720 --> 00:11:21,519
고품질 일반화를 얻기 위해 네트워크.

354
00:11:19,279 --> 00:11:23,279


355
00:11:21,519 --> 00:11:24,560
경험은 이 아이디어를 구현하는 간단한 기술을 재생합니다.

356
00:11:23,279 --> 00:11:26,079


357
00:11:24,560 --> 00:11:27,760
나중에 우리가 플레이한 경험에 대해 배울 것입니다.

358
00:11:26,079 --> 00:11:29,760


359
00:11:27,760 --> 00:11:31,360
인간 교사가 제공하는 교육적 훈련 사례

360
00:11:29,760 --> 00:11:33,839


361
00:11:31,360 --> 00:11:35,200
상당한 속도 향상을 가져올 수 있습니다.

362
00:11:33,839 --> 00:11:36,800
그것이 바로 우리가 커리큘럼 학습

363
00:11:35,200 --> 00:11:39,360
또는 모방 학습이라고 부르는 것입니다.

364
00:11:36,800 --> 00:11:40,560
계층적 학습, 강화 학습 에이전트는

365
00:11:39,360 --> 00:11:42,480


366
00:11:40,560 --> 00:11:43,519
계층적 학습으로 학습 시간을 크게 줄입니다.

367
00:11:42,480 --> 00:11:45,040


368
00:11:43,519 --> 00:11:46,640
의 최첨단 연구 주제입니다.

369
00:11:45,040 --> 00:11:48,560
오늘 딥 RL.

370
00:11:46,640 --> 00:11:50,079
강화 학습 에이전트는 다음을 처리할 수 있습니다.

371
00:11:48,560 --> 00:11:50,880
다양한 non-markovian으로

372
00:11:50,079 --> 00:11:52,800
자신의 과거에 대한 기억을 가지고 환경과

373
00:11:50,880 --> 00:11:54,480


374
00:11:52,800 --> 00:11:56,160
우리는 기억과 반복을 딥 러닝에

375
00:11:54,480 --> 00:11:58,240
통합하는 것에 대해 이야기할 것입니다.

376
00:11:56,160 --> 00:12:00,240
행동 양식.

377
00:11:58,240 --> 00:12:02,240
물론 이러한 방법은 과거에도 엄청난 성공을 거뒀습니다.

378
00:12:00,240 --> 00:12:04,079


379
00:12:02,240 --> 00:12:05,360
앞서 언급한 td gammon 시스템과

380
00:12:04,079 --> 00:12:06,560
같이 실제로 완료되었습니다.

381
00:12:05,360 --> 00:12:10,480
알파고보다 20년 이상 앞서 1996년

382
00:12:06,560 --> 00:12:11,920


383
00:12:10,480 --> 00:12:13,920
그러나 최근 몇 년 동안 우리는

384
00:12:11,920 --> 00:12:15,360
꽤 놀라운 발전을 보았습니다.

385
00:12:13,920 --> 00:12:16,800
동영상 재생을 직접 학습할 수

386
00:12:15,360 --> 00:12:19,200
있는 심층 강화 학습 알고리즘

387
00:12:16,800 --> 00:12:20,880
원시 이미지 픽셀에서 직접

388
00:12:19,200 --> 00:12:23,920
게임을 배울 수 있는 로봇 시스템

389
00:12:20,880 --> 00:12:27,120
고도로 일반화 가능한 기술 및

390
00:12:23,920 --> 00:12:28,720
심층 강화 학습 알고리즘의 범위

391
00:12:27,120 --> 00:12:37,360
이동 중에도 세계 챔피언을 이길 수 있습니다.

392
00:12:28,720 --> 00:12:37,360

