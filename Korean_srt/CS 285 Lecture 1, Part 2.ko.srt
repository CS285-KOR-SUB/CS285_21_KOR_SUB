1
00:00:01,199 --> 00:00:06,580
그렇다면 왜 우리는 심층 강화 학습에 관심을 가져야 할까요?

2
00:00:06,720 --> 00:00:09,220
특히 이 수업의 제목에 Deep이 있는 만큼,
이에 대해 조금 이야기합시다.

3
00:00:10,000 --> 00:00:12,900
그리고 이 주제에 대해 강의하기 앞서,
좀 더 큰 범위에서 질문을 해봅시다.

4
00:00:13,000 --> 00:00:18,100
그리고 이 질문은 우리가 첫 번째 강의에서도
몇 번 언급했던 것입니다.

5
00:00:18,240 --> 00:00:21,820
지능형 기계는 어떻게 만들까요?

6
00:00:21,840 --> 00:00:24,880
이 말은 앞서 언급했던 말 그대로

7
00:00:24,880 --> 00:00:28,819
우리가 만화에서 볼 수 있거나,

8
00:00:28,960 --> 00:00:34,280
로봇 집사, 의료목적의 로봇 도우미,

9
00:00:34,320 --> 00:00:38,060
혹은 공상 과학 영화에 나오는
우주선을 조종하는 로봇 같은 지능형 기계를 의미합니다.

10
00:00:38,079 --> 00:00:44,479
아니면 좀 더 장난꾸러기 성향이 있다면
사악한 로봇 악당도 될 수 있겠네요.

11
00:00:44,559 --> 00:00:46,079
지능형 기계는 여러 상황에 적응할 수 있어야 합니다.

12
00:00:46,079 --> 00:00:48,060
지능형 기계들은 세계의 복잡성과 불확실성에 대해서

13
00:00:48,079 --> 00:00:52,000
유연하게 현실 세계의 복잡성과 예측 불가능성을
유연하게 처리할 수 있어야 합니다.

14
00:00:52,079 --> 00:00:55,640
예를 들어, 자율 주행 유조선을 만들고 싶다면

15
00:00:56,079 --> 00:00:57,420
사실, 이것은 현재 아마 그리 어려운 것이 아닙니다.

16
00:00:58,240 --> 00:01:00,520
인간에게 어떻게 지구의 반대편에 떨어져 있는 곳으로

17
00:01:00,559 --> 00:01:04,140
바다를 항해하여 도착할 것인지 알아내는 것은 어려운 일이지만,

18
00:01:04,239 --> 00:01:09,359
GPS와 모션 플래닝의 조합으로
합리적으로 이 문제를 잘 해결할 수 있습니다.

19
00:01:09,360 --> 00:01:12,779
그러나 대부분의 유조선에는 여전히 사람이 타고 있습니다.

20
00:01:12,799 --> 00:01:14,380
왜 그럴까요?

21
00:01:14,479 --> 00:01:17,020
왜냐하면, 뭔가 잘못된 상황이 엔진룸에서 발생했을 때,

22
00:01:17,040 --> 00:01:19,180
우리는 그곳에 내려가 문제를 고칠 사람이 필요합니다.

23
00:01:19,459 --> 00:01:24,599
유조선을 항해하는 것은 비교적
어렵지 않은 인공지능 문제 이지만,

24
00:01:25,200 --> 00:01:31,680
현재 기술로 잘못되었을 때 수정하는 것은 매우 어렵습니다.

25
00:01:32,159 --> 00:01:36,400
이 어려움은 현실 세계가 구조화되지
않고 예측할 수 없기 때문입니다.

26
00:01:36,479 --> 00:01:40,059
그리고 현실세계의 구조화되지 않고,
예측 불가능한 특성을 처리할 수 있으면서,

27
00:01:40,079 --> 00:01:44,180
우리가 마음대로 사용할 수 있는 정말 강력한 기술이 바로
딥 러닝입니다.

28
00:01:44,240 --> 00:01:47,219
딥 러닝에서는 입력과 출력을 매핑하기 위해,

29
00:01:47,280 --> 00:01:51,979
심층 신경망과 같이 과도하게 over-paramiterized된
매우 큰 모델을 훈련시킵니다.

30
00:01:52,000 --> 00:01:55,099
예를 들어, 이미지에 개체를 인식하려는 경우

31
00:01:55,119 --> 00:01:58,420
많은 라벨링된 이미지를 수집한 다음,

32
00:01:58,479 --> 00:02:02,660
일반적으로, 지도 학습 방법을 사용하여 출력에서 입력을 예측합니다.

33
00:02:02,719 --> 00:02:04,540
하지만 딥러닝은 본질적으로

34
00:02:04,560 --> 00:02:08,919
알고리즘의 선택보다는
over-parameterized-model의 선택에 따릅니다.

35
00:02:09,439 --> 00:02:13,640
우리는 딥 러닝이 이미지 분류 부터 텍스트 번역,

36
00:02:13,660 --> 00:02:18,380
심지어 이미지상의 텍스트를 직접 번역하거나, 사람의 음성 인식에 이르기까지
다양한 부분에서 성공한 것을 알 수 있습니다.

37
00:02:18,480 --> 00:02:20,440
그리고 이것들은 오픈 월드 세팅입니다.

38
00:02:20,480 --> 00:02:25,598
다시말해, 전에 본 적이 없는 모든 종류의 특수한 경우와
비정상적인 상황이 발생할 수 있는 것들을

39
00:02:25,599 --> 00:02:31,299
효과적으로 일반화시킬 수 있는 모델이 필요합니다.

40
00:02:31,920 --> 00:02:34,100
강화 학습은 행동에 대한 formalism 제공합니다.

41
00:02:34,100 --> 00:02:39,279
앞서 언급했듯이 순차적 의사 결정에 대한 수학적 사고 방식을 제공합니다.

42
00:02:39,680 --> 00:02:44,200
강화 학습에서 agent는 세계와
상호 작용하고 관찰 및 보상을 얻습니다.

43
00:02:44,239 --> 00:02:49,320
그리고 이러한 방법들은
일반적이지 않 예측할 수 없는 상황을 유연하게 처리해야 하는

44
00:02:49,400 --> 00:02:56,599
다양한 응용 프로그램을 위해 심층 신경망과 함께 사용되었습니다.

45
00:02:56,600 --> 00:03:01,999
예를 들어, 일찍이 성공한 강화학습과 심층 신경망 조합 사례를 보면,

46
00:03:02,036 --> 00:03:05,555
보드게임 'backgammon'을 학습시켜 게임을 시킨 사례입니다.

47
00:03:05,580 --> 00:03:07,459
이것은 'TD gammon'이라는 시스템으로,

48
00:03:07,519 --> 00:03:10,760
챔피언 수준의 플레이어를 제압하는 수준이 아니지만,

49
00:03:10,800 --> 00:03:15,580
매우 전문적인  플레이어 수준으로
backgammon을 플레이하는 시스템입니다.

50
00:03:15,680 --> 00:03:21,340
바둑 2016에서 인간 챔피언을 물리친 Alphago의 기술은

51
00:03:21,360 --> 00:03:25,460
여러 면에서 90년대의 'TD gammon'과 많은 공통점이 있었습니다.

52
00:03:25,900 --> 00:03:31,240
심층 신경망을 사용하는 강화 학습 알고리즘을 의미하는 심층 강화 학습 방법은

53
00:03:31,280 --> 00:03:39,279
로봇 운동에서 비디오 게임을 하는 로봇 조작 기술에 이르기까지
다양한 작업에 사용되었습니다.

54
00:03:39,280 --> 00:03:43,919
그렇다면 deep RL은 정확히 무엇입니까?
그리고 왜 우리가 그것에 관심을 가져야 합니까?

55
00:03:44,000 --> 00:03:50,439
음, Deep RL의 중요성,
강화학습 방법의 차이점을 이해하기 위해,

56
00:03:50,440 --> 00:03:52,790
다른 도메인의 예부터 시작하겠습니다.

57
00:03:52,799 --> 00:04:01,419
컴퓨터 비전의 사례에서, 왜 심층 신경망이 머신 러닝 시스템의 성능에
혁신적인 영향을 끼치는지 알아보겠습니다.

58
00:04:01,920 --> 00:04:06,080
자 그럼, 약 15~20년 전으로 돌아가, 
컴퓨터 비전이 어땠는지 살펴보면

59
00:04:06,159 --> 00:04:08,720
다음과 같은 것들을 볼 수 있었을 것입니.

60
00:04:08,720 --> 00:04:12,559
이미지의 픽셀로 시작한 다음 해당 픽셀에서 예를 들어

61
00:04:12,640 --> 00:04:17,999
방향이 지정된 그라디언트의 히스토그램과 같이 
손으로 디자인한 low-level 시각적 기능을 추출합니다.

62
00:04:18,000 --> 00:04:23,220
그런 다음 일부 변형 가능한 부품 같이, 
mid-level 기능을 추출할 수 있습니다.

63
00:04:23,280 --> 00:04:25,060
그리고 mid-level 기능 위에서

64
00:04:25,120 --> 00:04:28,000
Support Vector Machine과 같은 간단한 선형분류기를 훈련시

65
00:04:28,000 --> 00:04:32,580
여러분들 원하는대로 분류하도록 할 수 있습니다.

66
00:04:32,639 --> 00:04:37,600
이제 딥 러닝으로 심층 신경망은

67
00:04:35,840 --> 00:04:39,520
거의 동일한 기능을 수행합니다.

68
00:04:37,600 --> 00:04:40,639
내부적으로는 중간 수준의 기능을 가지고 있으며

69
00:04:39,520 --> 00:04:42,639
저수준 기능과 분류기의 차이점은

70
00:04:40,639 --> 00:04:44,000


71
00:04:42,639 --> 00:04:46,800
이제 손으로 디자인할 필요가 없습니다.

72
00:04:44,479 --> 00:04:48,560
그들은 실제로

73
00:04:46,800 --> 00:04:50,160
심층 신경망.

74
00:04:48,560 --> 00:04:52,000
이것은 우리가 이러한 모든 것을 설계하는 데 많은

75
00:04:50,160 --> 00:04:52,960
인간의 노력을 절약한다는 것을 의미할 뿐만 아니라

76
00:04:52,000 --> 00:04:54,880
특징.

77
00:04:52,960 --> 00:04:56,320
그러나 그것은 또한 기능이 그들이 수행하는

78
00:04:54,880 --> 00:04:57,600
작업에 최적으로 적용된다는 것을 의미합니다.

79
00:04:56,320 --> 00:04:58,960
실제로 해결해야 합니다.

80
00:04:57,600 --> 00:05:00,800
따라서 일반적인 히스토그램이나

81
00:04:58,960 --> 00:05:01,919
성분 기능을 얻을 수 없습니다.

82
00:05:00,800 --> 00:05:06,320
재규어에서 호랑이를 분류하기

83
00:05:01,919 --> 00:05:07,680
위한 올바른 기능을 얻으십시오.

84
00:05:06,320 --> 00:05:09,520
이제 이 강의가 강화 학습 설정에

85
00:05:07,680 --> 00:05:10,120
어떻게 매핑되는지 생각해 보겠습니다.

86
00:05:10,160 --> 00:05:13,379
주사위 놀이에 대해 생각해 봅시다.

87
00:05:13,520 --> 00:05:16,720
표준 강화 학습 방법을 사용하려면

88
00:05:14,479 --> 00:05:18,160


89
00:05:16,720 --> 00:05:19,759
어떻게든 주사위 놀이 게임에서 기능을 추출해야 합니다.

90
00:05:18,160 --> 00:05:21,840


91
00:05:19,759 --> 00:05:23,440
어떤 종류의 기능을 사용합니까?

92
00:05:21,840 --> 00:05:24,720
글쎄, 아마도 당신이 주사위 놀이를하는

93
00:05:23,440 --> 00:05:26,160
사람이라면 다음이 있다는 것을 알고있을 것입니다.

94
00:05:24,720 --> 00:05:27,759
게임에서 중요한 몇 가지 나는 전문

95
00:05:26,160 --> 00:05:29,039
주사위 놀이 플레이어가 아니므로

96
00:05:27,759 --> 00:05:30,320
그것들이 무엇인지 모르지만 아마도

97
00:05:29,039 --> 00:05:30,800
그것들이 무엇인지 알고 있을 것입니다.

98
00:05:30,320 --> 00:05:33,360
당신은 그것들을 기록할 수 있습니다.

99
00:05:30,800 --> 00:05:33,620


100
00:05:32,460 --> 00:05:34,700
하지만 중요하다고 생각하는 기능만

101
00:05:34,320 --> 00:05:36,800
있는 것만으로는 충분하지 않습니다.

102
00:05:35,600 --> 00:05:37,440
게임의 경우 기능도 있어야 합니다.

103
00:05:36,800 --> 00:05:40,320


104
00:05:37,440 --> 00:05:41,840
정책 가치 기능 및 기타 객체를

105
00:05:40,320 --> 00:05:43,360
나타내는 데 사용할 수 있습니다.

106
00:05:41,840 --> 00:05:44,400
몇 가지 간단한 방법으로 강화 학습과 관련이 있습니다.

107
00:05:43,360 --> 00:05:47,440


108
00:05:44,400 --> 00:05:48,800
표 또는 선형 표현처럼.

109
00:05:47,440 --> 00:05:50,880
그리고 그것은 훨씬 더 어려운 디자인입니다.

110
00:05:48,800 --> 00:05:53,360
왜냐하면 지금 당신은 단지 디자인 뿐만 아니라

111
00:05:50,880 --> 00:05:55,520
전문가이자 주사위 놀이 뿐만 아니라

112
00:05:53,360 --> 00:05:56,880
강화 학습의 전문가이기도 합니다.

113
00:05:55,520 --> 00:05:59,039
그리고 어떤 기능이 좋은지에 대한 많은 직관이 필요합니다.

114
00:05:56,880 --> 00:06:00,560


115
00:05:59,039 --> 00:06:02,080
이것은 실제로 매우 어려운 것으로 밝혀졌고 오랫동안

116
00:06:00,560 --> 00:06:03,039


117
00:06:02,080 --> 00:06:04,800
강화 학습 방법을 적용하기가 매우 어렵습니다.

118
00:06:03,039 --> 00:06:07,680


119
00:06:04,800 --> 00:06:09,360
복잡한 문제에.

120
00:06:07,680 --> 00:06:11,600
딥 러닝은 강화 학습에 했던

121
00:06:09,360 --> 00:06:13,360
것과 동일한 공식을 적용합니다.

122
00:06:11,600 --> 00:06:14,720
수동 기능을 대체하는 컴퓨터 임무 문제에

123
00:06:13,360 --> 00:06:15,520


124
00:06:14,720 --> 00:06:17,199
자동으로 학습된 기능으로 추출

125
00:06:15,520 --> 00:06:18,880


126
00:06:17,199 --> 00:06:21,440
심층 신경망으로 표현하고 종단 간 훈련.

127
00:06:18,880 --> 00:06:23,199


128
00:06:21,440 --> 00:06:24,479
그러나 일반적으로 광범위한 문제에 대한 강화 학습 설정에서

129
00:06:23,199 --> 00:06:26,160


130
00:06:24,479 --> 00:06:27,360
기능 설계에 대한 직관을 처리하려는

131
00:06:26,160 --> 00:06:29,039


132
00:06:27,360 --> 00:06:33,280
컴퓨터 비전보다 훨씬 약하며

133
00:06:30,960 --> 00:06:34,319
이러한 이유로 심층 강화 학습 방법은

134
00:06:33,280 --> 00:06:35,919
강화 학습 알고리즘의 기능에 대한 변형 효과.

135
00:06:34,319 --> 00:06:38,319


136
00:06:39,200 --> 00:06:46,400
그렇다면 순차 의사 결정에서
종단 간 학습은 무엇을 의미합니까?

137
00:06:43,600 --> 00:06:49,199
음, 먼저 의도된 학습이 없다는 것이

138
00:06:46,400 --> 00:06:50,319
무엇을 의미하는지 설명하겠습니다.

139
00:06:49,199 --> 00:06:51,680
의도한 학습이 없을 때 처리해야 함을 의미합니다.

140
00:06:50,319 --> 00:06:53,039


141
00:06:51,680 --> 00:06:54,880
문제의 인식 부분과 문제의 제어 부분을 별도로 분리합니다.

142
00:06:53,039 --> 00:06:57,440


143
00:06:54,880 --> 00:06:58,560
그래서 아마도 당신은 당신이 보고 있는 것을

144
00:06:57,440 --> 00:07:00,560
알아내는 하나의 시스템을 가지고 있을 것입니다.

145
00:06:58,560 --> 00:07:02,720
이미지 당신은 호랑이, 재규어

146
00:07:00,560 --> 00:07:04,400
또는 무해한 것을 보고 있습니까?

147
00:07:02,720 --> 00:07:06,160
실제로 무엇을 기반으로 할 것인지 결정하는

148
00:07:04,400 --> 00:07:09,360
또 다른 구성 요소로 연결되는 파이프라인

149
00:07:06,160 --> 00:07:09,360
그 지각적 결과에 대해.

150
00:07:09,520 --> 00:07:12,639
그리고 여러분은 여러분의 지각

151
00:07:11,360 --> 00:07:13,440
체계를 좋은 지각 체계로 훈련시키고

152
00:07:12,639 --> 00:07:14,800
보고 있는 것을 정확하게 인식하고

153
00:07:13,440 --> 00:07:16,479


154
00:07:14,800 --> 00:07:18,400
제어 시스템이 올바른 조치를 취하기 위한

155
00:07:16,479 --> 00:07:19,759
좋은 제어 시스템이 되도록 훈련하십시오.

156
00:07:18,400 --> 00:07:21,680
그러나 지각 시스템은 별도로 훈련되기 때문에

157
00:07:19,759 --> 00:07:22,560


158
00:07:21,680 --> 00:07:24,800
그것이 알지 못하는 행동 체계의 요구

159
00:07:22,560 --> 00:07:26,000


160
00:07:24,800 --> 00:07:27,120
어떤 종류의 탐지가 중요한지,

161
00:07:26,000 --> 00:07:29,599
어떤 종류가 중요하지 않은지,

162
00:07:27,120 --> 00:07:30,960
어떤 종류의 실수가 비용이 많이 들고

163
00:07:29,599 --> 00:07:32,560
어떤 종류의 실수가 비용이 덜 듭니다.

164
00:07:30,960 --> 00:07:35,680
그리고 그것은 우리가 호랑이에게서

165
00:07:32,560 --> 00:07:35,680
도망쳐야 하는 큰 일입니다.

166
00:07:35,759 --> 00:07:38,720
강렬한 시스템은 감각 운동 루프를 닫지만 실제로는

167
00:07:37,680 --> 00:07:40,240


168
00:07:38,720 --> 00:07:42,400
전체 시스템 종단 간

169
00:07:40,240 --> 00:07:43,759
지각과 통제를 동시에 수행

170
00:07:42,400 --> 00:07:46,319


171
00:07:43,759 --> 00:07:48,000
작업의 최종 수행에 의해 직접 정보를 받는 행동 특징.

172
00:07:46,319 --> 00:07:51,440


173
00:07:50,000 --> 00:07:53,039
다음은 몇 가지 예시적인 애플리케이션

174
00:07:51,440 --> 00:07:54,240
시나리오에서 의미하는 바입니다.

175
00:07:53,039 --> 00:07:56,160
로봇 제어 기존 로봇 파이프라인은

176
00:07:54,240 --> 00:07:57,440


177
00:07:56,160 --> 00:07:59,680
를 추정하는 관찰을 수행하는 단계로 구성됩니다.

178
00:07:57,440 --> 00:08:01,759


179
00:07:59,680 --> 00:08:02,960
약간의 모델링 및 예측을 수행하는 객체의 위치와 같은 상태

180
00:08:01,759 --> 00:08:04,720


181
00:08:02,960 --> 00:08:06,000
해당 객체가 미래에 어떻게 동작할지 파악

182
00:08:04,720 --> 00:08:05,960


183
00:08:06,000 --> 00:08:08,600
해당 모델링 및 예측을 기반으로 일부 계획 수행

184
00:08:08,939 --> 00:08:11,960
그 위에 몇 가지 낮은 수준의 제어를 수행하는 등

185
00:08:12,100 --> 00:08:15,979
중요한 것은 이 프로세스의 각 단계에서
약간의 오류가 발생할 수 있다는 것입니다.

186
00:08:16,100 --> 00:08:20,120
물체가 어디에 있는지 감지하는 데 실수를 할 수 있습니다.

187
00:08:16,479 --> 00:08:20,879


188
00:08:18,720 --> 00:08:22,400
그 시점에서 당신이 구성하는 계획은

189
00:08:20,879 --> 00:08:23,680


190
00:08:22,400 --> 00:08:25,360
그것은 잘못된 전제에 기반을

191
00:08:23,680 --> 00:08:26,960
두고 있기 때문에 현실 세계입니다.

192
00:08:25,360 --> 00:08:28,560
인텐트 접근 방식은 이 문제를 극복할 수 있습니다.

193
00:08:26,960 --> 00:08:30,479


194
00:08:28,560 --> 00:08:31,759
이 파이프라인의 각 단계는

195
00:08:30,479 --> 00:08:33,120
다음 요구 사항에 따라 알려집니다.

196
00:08:31,759 --> 00:08:33,100
라인 아래로 단계.

197
00:08:33,120 --> 00:08:34,740
따라서 로봇 제어에 대한 심층 강화

198
00:08:34,800 --> 00:08:37,539
학습 접근 방식을 상상할 수 있습니다.

199
00:08:37,599 --> 00:08:42,719
지각과 행동을 모두 수행하는

200
00:08:40,640 --> 00:08:44,320
컨볼루션 심층 신경망이 있는 곳입니다.

201
00:08:42,719 --> 00:08:46,080
따라서 로봇 카메라의 이미지는 이

202
00:08:44,320 --> 00:08:49,279
네트워크의 맨 아래에 맞춰집니다.

203
00:08:46,080 --> 00:08:51,200
끝에서 나오는 출력은 로봇의 액츄에이터에 공급됩니다.

204
00:08:49,279 --> 00:08:53,680


205
00:08:51,200 --> 00:08:54,640
이러한 종류의 감각 운동 루프는 다음을 나타냅니다.

206
00:08:53,680 --> 00:08:56,320


207
00:08:54,640 --> 00:08:57,920
약간의 시각적 구성 요소가 있는

208
00:08:56,320 --> 00:08:59,279
이 로봇을 위한 두뇌의 작은 축소판

209
00:08:57,920 --> 00:09:00,880
작은 행동 요소.

210
00:08:59,279 --> 00:09:02,800
그러나 그들 모두는 엔드 투 엔드 교육을 받았습니다.

211
00:09:00,880 --> 00:09:04,160
작업의 최종 수행을 위해.

212
00:09:02,800 --> 00:09:06,320
따라서 매우 긴장된 비유를 사용하기

213
00:09:04,160 --> 00:09:08,000
위해 컨볼루션 레이어를 생각할 수 있습니다.

214
00:09:06,320 --> 00:09:10,240
일종의 고도로 전문화된 시각 피질과 완전히 연결된

215
00:09:08,000 --> 00:09:11,839


216
00:09:10,240 --> 00:09:12,959
층은 아주 작은 고도로 전문화된 운동 피질입니다.

217
00:09:11,839 --> 00:09:14,720


218
00:09:12,959 --> 00:09:16,080
하지만 그들은 모두 훈련을 받았고 끝내야 하기 때문에 결국

219
00:09:14,720 --> 00:09:17,600


220
00:09:16,080 --> 00:09:18,880
그들의 능력 내에서 작업에 가장 적합한 것은 무엇이든

221
00:09:17,600 --> 00:09:20,640


222
00:09:18,880 --> 00:09:21,839
대표 능력.

223
00:09:20,640 --> 00:09:24,000
따라서 로봇은 이 작업을 수행하는

224
00:09:21,839 --> 00:09:26,399
경험을 통해 학습할 수 있습니다.

225
00:09:24,000 --> 00:09:27,200
그리고 그것을 사용하여 이 네트워크의

226
00:09:26,399 --> 00:09:29,279
모든 가중치를 끝에서 끝까지 훈련합니다.

227
00:09:30,240 --> 00:09:34,880
강화 문제의 이러한 어 예제

228
00:09:32,640 --> 00:09:37,519
응용 프로그램에 대해 생각해 보면,

229
00:09:34,880 --> 00:09:39,440
심층 신경망 표현과 결합하면

230
00:09:37,519 --> 00:09:42,000


231
00:09:39,440 --> 00:09:42,959
강화 학습 시스템은 실제로

232
00:09:42,000 --> 00:09:44,959


233
00:09:42,959 --> 00:09:47,040
어떤 의미에서 AI 문제의 전체.

234
00:09:44,959 --> 00:09:48,000
지도 학습 시스템에는 다음이 필요합니다.

235
00:09:47,040 --> 00:09:50,160


236
00:09:48,000 --> 00:09:51,120
입력 및 출력 감독.

237
00:09:50,160 --> 00:09:53,600
강화 학습 시스템은 의존하지

238
00:09:51,120 --> 00:09:55,360
않고 최적의 행동을 목표로 합니다.

239
00:09:53,600 --> 00:09:57,920
보상 피드백에 의존하기 위해 그러한 감독에 대해.

240
00:09:55,360 --> 00:09:59,120


241
00:09:57,920 --> 00:10:01,200
그리고 심층 모델은 강화 학습 알고리즘이

242
00:09:59,120 --> 00:10:02,720


243
00:10:01,200 --> 00:10:03,760
복잡한 문제를 끝까지

244
00:10:02,720 --> 00:10:05,680
강화 학습은 수학적 형식을 제공합니다.

245
00:10:03,760 --> 00:10:06,959


246
00:10:05,680 --> 00:10:08,480
심층 모델이 제공하는 동안 알고리즘 기반

247
00:10:06,959 --> 00:10:10,160


248
00:10:08,480 --> 00:10:11,360
이러한 알고리즘 기반을 허용하는 표현

249
00:10:10,160 --> 00:10:15,120


250
00:10:11,360 --> 00:10:15,120
실제 시스템으로 확장할 수 있습니다.

251
00:10:16,079 --> 00:10:19,000
그렇다면 왜 지금 이러한 질문을 연구해야 합니까?

252
00:10:19,200 --> 00:10:22,399
글쎄요, 지난 10년 동안 많은 발전이 있었습니다.

253
00:10:20,720 --> 00:10:23,839


254
00:10:22,399 --> 00:10:25,360
이것은 심층 강화 학습을

255
00:10:23,839 --> 00:10:26,480
연구하기에 정말 흥미로운 시간입니다.

256
00:10:25,360 --> 00:10:28,720
첫째, 딥러닝 자체에서 엄청난 발전이 있었습니다.

257
00:10:26,480 --> 00:10:31,440


258
00:10:28,720 --> 00:10:33,360
심층 신경망 표현을 구축하는 방법.

259
00:10:30,640 --> 00:10:33,359


260
00:10:33,360 --> 00:10:36,399
강화 학습 알고리즘에도 많은 발전이 있었습니다.

261
00:10:34,959 --> 00:10:37,839


262
00:10:36,399 --> 00:10:38,060
이러한 딥 러닝 표현을 사용하여

263
00:10:37,839 --> 00:10:40,780
이러한 방법을 확장할 수 있습니다.

264
00:10:40,880 --> 00:10:43,920
마지막으로 컴퓨팅 능력의 발전

265
00:10:43,120 --> 00:10:45,279


266
00:10:43,920 --> 00:10:49,200
이 두 요소를 결합하는 것이 그 어느

267
00:10:45,279 --> 00:10:49,200
때보다 실용적으로 만들어졌습니다.

268
00:10:49,360 --> 00:10:52,959
딥 강화 학습의 기본 기반은

269
00:10:51,279 --> 00:10:54,160


270
00:10:52,959 --> 00:10:55,760
새로운 것을 의미합니다.

271
00:10:54,160 --> 00:10:57,519
예를 들어 제어를 위한 신경망에 대한 교과서가 있습니다.

272
00:10:55,760 --> 00:10:58,880


273
00:10:57,519 --> 00:11:00,720
수십 년 전으로 돌아가

274
00:10:58,880 --> 00:11:03,440
1980년대.

275
00:11:00,720 --> 00:11:04,560
그리고 90년대의 작업에서도

276
00:11:03,440 --> 00:11:07,040
실제로 많은 논의가 이루어졌습니다.

277
00:11:04,560 --> 00:11:08,560
예를 들어 오늘날 최첨단 연구의 일부인 성분

278
00:11:07,040 --> 00:11:09,680


279
00:11:08,560 --> 00:11:12,560
1993년의 박사 학위 논문은

280
00:11:09,680 --> 00:11:13,920
현대에 필요한 몇 가지를 말합니다.

281
00:11:12,560 --> 00:11:15,519
심층 강화 학습 연구원은 다음과 같이 매우 친숙합니다.

282
00:11:13,920 --> 00:11:17,519


283
00:11:15,519 --> 00:11:18,720
강화 학습은 인공 신경과 자연스럽게 통합될 수 있습니다.

284
00:11:17,519 --> 00:11:19,279


285
00:11:18,720 --> 00:11:21,519
고품질 일반화를 얻기 위해 네트워크.

286
00:11:19,279 --> 00:11:23,279


287
00:11:21,519 --> 00:11:24,560
경험은 이 아이디어를 구현하는 간단한 기술을 재생합니다.

288
00:11:23,279 --> 00:11:26,079


289
00:11:24,560 --> 00:11:27,760
나중에 우리가 플레이한 경험에 대해 배울 것입니다.

290
00:11:26,079 --> 00:11:29,760


291
00:11:27,760 --> 00:11:31,360
인간 교사가 제공하는 교육적 훈련 사례

292
00:11:29,760 --> 00:11:33,839


293
00:11:31,360 --> 00:11:35,200
상당한 속도 향상을 가져올 수 있습니다.

294
00:11:33,839 --> 00:11:36,800
그것이 바로 우리가 커리큘럼 학습

295
00:11:35,200 --> 00:11:39,360
또는 모방 학습이라고 부르는 것입니다.

296
00:11:36,800 --> 00:11:40,560
계층적 학습, 강화 학습 에이전트는

297
00:11:39,360 --> 00:11:42,480


298
00:11:40,560 --> 00:11:43,519
계층적 학습으로 학습 시간을 크게 줄입니다.

299
00:11:42,480 --> 00:11:45,040


300
00:11:43,519 --> 00:11:46,640
의 최첨단 연구 주제입니다.

301
00:11:45,040 --> 00:11:48,560
오늘 딥 RL.

302
00:11:46,640 --> 00:11:50,079
강화 학습 에이전트는 다음을 처리할 수 있습니다.

303
00:11:48,560 --> 00:11:50,880
다양한 non-markovian으로

304
00:11:50,079 --> 00:11:52,800
자신의 과거에 대한 기억을 가지고 환경과

305
00:11:50,880 --> 00:11:54,480


306
00:11:52,800 --> 00:11:56,160
우리는 기억과 반복을 딥 러닝에

307
00:11:54,480 --> 00:11:58,240
통합하는 것에 대해 이야기할 것입니다.

308
00:11:56,160 --> 00:12:00,240
행동 양식.

309
00:11:58,240 --> 00:12:02,240
물론 이러한 방법은 과거에도 엄청난 성공을 거뒀습니다.

310
00:12:00,240 --> 00:12:04,079


311
00:12:02,240 --> 00:12:05,360
앞서 언급한 td gammon 시스템과

312
00:12:04,079 --> 00:12:06,560
같이 실제로 완료되었습니다.

313
00:12:05,360 --> 00:12:10,480
알파고보다 20년 이상 앞서 1996년

314
00:12:06,560 --> 00:12:11,920


315
00:12:10,480 --> 00:12:13,920
그러나 최근 몇 년 동안 우리는

316
00:12:11,920 --> 00:12:15,360
꽤 놀라운 발전을 보았습니다.

317
00:12:13,920 --> 00:12:16,800
동영상 재생을 직접 학습할 수

318
00:12:15,360 --> 00:12:19,200
있는 심층 강화 학습 알고리즘

319
00:12:16,800 --> 00:12:20,880
원시 이미지 픽셀에서 직접

320
00:12:19,200 --> 00:12:23,920
게임을 배울 수 있는 로봇 시스템

321
00:12:20,880 --> 00:12:27,120
고도로 일반화 가능한 기술 및

322
00:12:23,920 --> 00:12:28,720
심층 강화 학습 알고리즘의 범위

323
00:12:27,120 --> 00:12:37,360
이동 중에도 세계 챔피언을 이길 수 있습니다.

324
00:12:28,720 --> 00:12:37,360

