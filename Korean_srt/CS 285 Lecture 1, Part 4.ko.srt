1
00:00:01,360 --> 00:00:04,000
그래서 이 첫 번째 강의 모듈의 마지막 부분에서

2
00:00:04,000 --> 00:00:09,840
저는 이전에 우리가 어떻게 지능형 기계를 만들 수 있는지 물었던 질문으로 돌아가고 싶습니다.

3
00:00:09,840 --> 00:00:19,039
우리가 강화 학습 등 학습에 대해 알고 있는 모든 것을 잊어버리고 엔지니어와 같이 이 문제에 대해 정말로 생각한다면

4
00:00:19,039 --> 00:00:22,640
어디서부터 시작해서 지능형 기계를 구축해야 할까요.

5
00:00:22,640 --> 00:00:29,359
아마도 매우 논리적인 출발점은 인간의 뇌에서 하는 모든 일에 대해 생각하는 것입니다

6
00:00:29,359 --> 00:00:31,359
그것들을 독립적인 모듈로 생각하십시오.

7
00:00:31,359 --> 00:00:42,800
뇌를 개별 부분으로 분해하고 그 기능에 대해 생각하는 것은 아주 오래된 연구이며 현대 과학 시대 이전으로 거슬러 올라가는 것을 수행하는 모듈을 프로그래밍 할 수 있습니다.

8
00:00:42,800 --> 00:00:46,879
물론 오늘날의 이해는 19세기보다 조금 더 정교합니다.

9
00:00:46,879 --> 00:00:52,399
하지만 해부학적으로 뇌를 다양한 기능을 가진 부분으로 자르기 위해 많은 노력이 필요합니다.

10
00:00:52,399 --> 00:00:59,039
따라서 엔지니어로서 이러한 기능을 재현하기 위해 개별 컴퓨터 구성 요소를 구축하는 것에 대해 생각하는 것은 매우 유혹적입니다.

11
00:00:59,039 --> 00:01:00,719
그러나 이것은 곧 매우 어려워집니다.

12
00:01:00,719 --> 00:01:05,680
이러한 부분이 많기 때문에 각각을 구현하는 것은 매우 어렵습니다.

13
00:01:05,680 --> 00:01:11,439
그리고 그것들을 모두 구현하려면 엄청난 양의 작업이 필요할 수 있습니다.

14
00:01:11,439 --> 00:01:17,119
대신 학습이 지능의 기초로 간주될 수 있는지 고려한다면 어떨까요?

15
00:01:17,119 --> 00:01:24,640
나는 이것이 사실일 수 있는 이유에 대해 논증할 것입니다. 이것은 결코 널리 받아 들여지거나 보편적으로 받아 들여지는 의견이 아닙니다.

16
00:01:24,640 --> 00:01:29,040
하지만 아마도 당신은 우리가 그 개념을 즐겁게 할 수 있고 그것이 우리를 어디로 이끄는지 알 수 있다는 것을 알고 있을 것입니다.

17
00:01:29,040 --> 00:01:32,799
우리가 이 개념을 주장할 수 있는 한 가지 방법은 우리 모두가 걷기처럼 할 수 있는 몇 가지가 있다고 말하는 것입니다.

18
00:01:32,799 --> 00:01:37,040
하지만 분명히 우리가 배워야 할 몇 가지 다른 것들이 있습니다.

19
00:01:37,040 --> 00:01:42,240
인간이 진화를 통해 차를 운전하는 것과 같은 일에 대비할 수 있는 방법이 없기 때문입니다.

20
00:01:42,240 --> 00:01:45,360
우리가 진화했을 때 자동차는 주변에 없었습니다.

21
00:01:45,360 --> 00:01:48,399
제가 하고자 하는 말은 우리가 엄청나게 다양한 것들을 배울 수 있다는 것입니다.

22
00:01:48,399 --> 00:01:53,439
우리가 배울 수 있는 두 번째 범주는 매우 큰 범주입니다. 우리가 배울 수 있는 것은 매우 다양합니다.

23
00:01:53,439 --> 00:01:55,600
매우 어려운 일을 포함합니다.

24
00:01:55,600 --> 00:02:02,880
우리가 논쟁하거나 타고난 것들이 있을 수 있지만 우리가 배울 수 있는 것의 범위는 너무 광범위하여 기본적으로 우리가 관심 있는 모든 것을 포착할 수 있습니다.

25
00:02:02,880 --> 00:02:07,920
그리고 선천적인 것들은 시작할 나이가 아니었어도 배울 수 있었을 것입니다.

26
00:02:07,920 --> 00:02:14,160
따라서 우리의 학습 메커니즘은 기본적으로 우리가 지능과 연관시키는 모든 것을 할 수 있을 만큼 충분히 강력합니다.

27
00:02:14,160 --> 00:02:18,080
이 개념에 동의하거나 동의하지 않을 수도 있지만 잠시 이 개념을 유머러스하게 표현한다면

28
00:02:18,080 --> 00:02:26,480
인텔리전스를 구축하기 위한 계획을 구체화하기 위해 이를 어떻게 사용할지 생각할 수 있습니다.

29
00:02:26,480 --> 00:02:36,000
이제 우리는 이 레시피를 사용하여 각 모듈의 기능을 설계하는 대신 각 모듈에 대한 학습 알고리즘을 설계하여 괜찮다고 말할 수 있습니다.

30
00:02:36,000 --> 00:02:39,280
우리는 손으로 운동 피질의 시각 피질을 구현하지 않을 것입니다

31
00:02:39,280 --> 00:02:42,319
대신 우리가 구현할 것은 시각 피질에 대한 학습 알고리즘입니다.

32
00:02:42,384 --> 00:02:45,350
운동 피질에 대한 별도의 알고리즘입니다.

33
00:02:45,350 --> 00:02:51,680
이런 종류의 것은 90년대와 2000년대 초반에 기계 학습에 대한 지배적인 사고 방식이었습니다.

34
00:02:51,680 --> 00:02:56,959
하지만 이 모든 작업을 수행할 수 있는 유연한 단일 알고리즘이 있다고 가정하면 어떨까요?

35
00:02:56,959 --> 00:03:00,159
아마도 지능의 기초를 배우는 것뿐만 아니라

36
00:03:00,159 --> 00:03:04,239
대신에 지능의 기초로서 하나의 강력한 알고리즘을 사용하여 실제로 학습합니다.

37
00:03:04,239 --> 00:03:07,360
그것은 매우 도발적인 개념이지만 또한 매우 매력적인 개념이기도 합니다.

38
00:03:07,360 --> 00:03:09,440
많은 작업을 절약할 수 있음을 암시하기 때문입니다.

39
00:03:09,440 --> 00:03:18,000
각 모듈에 대해 별도의 알고리즘을 설계하는 대신 이러한 모든 기능을 획득할 수 있을 만큼 충분히 광범위하고 유연한 하나의 알고리즘을 설계하기만 하면 됩니다.

40
00:03:18,000 --> 00:03:25,040
그리고 이와 같은 것이 실제로 실제 뇌에서 일어나는 일과 비슷할 수 있음을 시사하는 약간의 증거가 있습니다.

41
00:03:25,040 --> 00:03:33,680
이것들은 모두 비정상적이거나 예상치 못한 어느 정도의 유연성을 설명하는 일반적인 풍미를 가지고 있는 이러한 증거입니다.

42
00:03:33,680 --> 00:03:41,120
예를 들어 혀를 사용하여 이 정도의 시력을 얻을 수 있습니다. 전극이 부착된 카메라를 찍을 수 있습니다.

43
00:03:41,120 --> 00:03:42,799
그리고 그 전극을 혀에 댑니다.

44
00:03:42,799 --> 00:03:44,640
그리고 눈을 감죠.

45
00:03:44,640 --> 00:03:47,200
또는 눈이 먼 경우 혀를 사용하여 볼 수 있습니다.

46
00:03:47,200 --> 00:03:49,599
그런 다음 몇 가지 시력 테스트를 수행합니다.

47
00:03:49,599 --> 00:03:54,720
그리고 실제로 약간의 연습으로 혀로 어느 정도의 시력을 얻게 될 것입니다.

48
00:03:54,720 --> 00:04:10,319
좀 더 극단적인 실험이라고 합니다. 공정하게 동물을 대상으로 한 더 극단적인 실험은 아주 어렸을 때 흰 족제비의 시신경이 시각 피질에서 분리되었다가 청각 피질에 외과적으로 다시 연결되었습니다.

49
00:04:10,319 --> 00:04:11,519
그런 다음 페럿이 자랐습니다.

50
00:04:11,519 --> 00:04:13,280
그리고 성장 과정에서

51
00:04:13,280 --> 00:04:16,239
실제로 시력을 어느 정도 회복했습니다.

52
00:04:16,239 --> 00:04:19,759
이것은 청각 피질이 본질적으로 보는 법을 배우고 있음을 의미합니다.

53
00:04:19,759 --> 00:04:23,759
따라서 서로 다른 센서 피질을 용도 변경하여 서로의 작업을 수행할 수 있다면

54
00:04:23,759 --> 00:04:28,320
어떤 의미에서 그들은 모두 동일한 유연한 알고리즘을 구현하고 있습니다.

55
00:04:28,320 --> 00:04:29,840
우리는 이 아이디어를 더 발전시킬 수 있습니다

56
00:04:29,840 --> 00:04:32,320
감각 피질뿐만 아니라

57
00:04:32,320 --> 00:04:36,880
그러나 실제로는 하나의 유연한 알고리즘으로 두뇌의 많은 기능을 수행할 수 있습니다.

58
00:04:36,880 --> 00:04:39,919
이것이 사실인지는 모르지만 매우 매력적인 개념입니다.

59
00:04:39,919 --> 00:04:43,680
이것이 사실이라면 어떤 종류의 알고리즘이 될 수 있는지 물어볼 수 있습니다.

60
00:04:43,680 --> 00:04:46,800
단일 알고리즘이 수행할 수 있어야 하는 것은 무엇일까요?

61
00:04:46,800 --> 00:04:53,520
풍부한 감각 입력을 해석할 수 있어야 하고 복잡하고 풍부한 오픈 월드 문제를 처리해야 합니다.

62
00:04:53,520 --> 00:05:03,360
복잡한 행동을 선택해야 합니다. 이는 의사 결정에 대해 추론하고 제어해야 한다는 것을 의미합니다.

63
00:05:03,360 --> 00:05:16,000
복잡한 개방형 세계 입력을 처리하고 강화 학습은 의사 결정 및 제어를 위한 형식을 제공합니다.

64
00:05:16,000 --> 00:05:27,520
그리고 사실 딥 러닝과 강화 학습 모두 적어도 개별적으로 뇌가 정보를 처리하는 방식에 대한 합리적인 모델을 제공한다는 정황 증거가 있습니다.

65
00:05:27,520 --> 00:05:40,960
그래서 이것은 뇌에 존재하는 것으로 알려진 종류의 특징을 분석하려고 시도하는 프라이머리 피질 수용체 필드 및 수용체 필드 가소성의 감독되지 않은 학습 모델이라고 불리는 이 시점에서 약 10년 된 오래된 논문입니다.

66
00:05:40,960 --> 00:06:03,600
그리고 그것들을 영장류의 센서 시체에서 관찰되는 특징의 종류와 비교합니다. 예를 들어 그들은 시각 피질의 개별 수용장을 자극하는 것으로 알려진 등급 유형 자극과 같은 간단한 자극을 받습니다.

67
00:06:03,600 --> 00:06:08,720
그리고 그들은 심층 신경망에 의해 이러한 자극으로부터 학습된 특징의 종류를 분석합니다.

68
00:06:08,720 --> 00:06:17,680
그런 다음 그들은 그 특징의 통계를 원숭이 실험에서 영장류 시각 피질에 존재하는 것으로 알려진 특징과 비교합니다.

69
00:06:17,680 --> 00:06:28,880
그들은 청각 기능에 대해 유사한 실험을 수행하여 심층 신경망을 다양한 청각 자극에 노출시킵니다. 나타나는 기능의 통계를 보고 이를 다시 뇌의 기능 통계와 비교합니다.

70
00:06:28,880 --> 00:06:38,800
그리고 그들은 촉각에 대한 재미있는 실험을 했습니다. 인간 대상을 잡고 흰 먼지를 뿌린 장갑으로 물체를 조작하게 했습니다.

71
00:06:38,800 --> 00:06:49,680
그리고 그들은 장갑에 먼지가 쌓인 곳을 사용하여 본질적으로 터치 감지 기능을 나타내도록 심층 신경망을 훈련시킵니다.

72
00:06:49,680 --> 00:06:57,919
그리고 그들은 원숭이의 손이 움푹 들어간 고막에 놓이는 원숭이에 대한 실험에서 존재하는 것으로 알려진 특징과 비교합니다.

73
00:06:57,919 --> 00:07:05,280
회전한 다음 원숭이의 촉각이 뇌의 뉴런에서 기록되고 다시 이 기능의 통계를 비교합니다.

74
00:07:05,280 --> 00:07:08,960
신경망이 유사한 통계를 가진 기능을 학습하는지 확인합니다.

75
00:07:08,960 --> 00:07:12,400
이제 이러한 실험에서 도출할 수 있는 몇 가지 결론이 있습니다.

76
00:07:12,400 --> 00:07:18,880
예를 들어 우리는 심층 신경망이 뇌가 작동하는 것과 같은 방식으로 작동한다고 결론을 내릴 수 있습니다.

77
00:07:18,880 --> 00:07:23,360
하지만 실제로는 더 간단한 설명이 있다고 생각합니다

78
00:07:23,360 --> 00:07:25,440
그것은 아마도 심층 신경망 자체에 관한 것이 아닐 것입니다.

79
00:07:25,440 --> 00:07:34,000
과적합 된 큰 모델이 이러한 통계를 사용하여 기능을 발견할 것이라는 관찰에 관한 것입니다.

80
00:07:34,000 --> 00:07:35,599
이 데이터에 딱 맞는 기능이기 때문입니다.

81
00:07:35,599 --> 00:07:39,199
따라서 어떤 의미에서 기능은 데이터 자체의 속성일 수 있습니다.

82
00:07:39,199 --> 00:07:46,319
내부 디자인에 관계없이 충분히 강력한 모델은 올바른 기능이기 때문에 이러한 기능을 획득할 것입니다.

83
00:07:46,319 --> 00:07:52,560
또한 뇌가 학습하는 방법의 모델로서 강화 학습에 찬성하는 증거가 꽤 있습니다.

84
00:07:52,560 --> 00:07:59,280
그리고 사실 강화 학습은 컴퓨터 과학을 연구하는 분야가 되기 훨씬 전에 심리학과 신경 과학에서 연구되었습니다.

85
00:07:59,280 --> 00:08:06,000
예상 보상이 보상 자체와 유사한 발사 패턴과 연관된다는 것을 인식합니다. 이것은 알려진 관찰입니다.

86
00:08:06,000 --> 00:08:09,360
때로는 스펙트럼 의존적 가소성이라고도 합니다.

87
00:08:09,360 --> 00:08:12,800
기저핵은 뇌의 보상 시스템과 관련이 있는 것으로 보입니다.

88
00:08:12,800 --> 00:08:22,000
적응과 같은 모델 3rl은 종종 동물 적응의 실험 데이터에 적합하지만 항상 그런 것은 아닙니다.

89
00:08:22,000 --> 00:08:33,919
좋습니다. 그래서 우리는 어떤 고객을 위해 이것으로부터 결론을 내릴 수 있습니다. 실제로 우리가 인간 지능과 연관시키는 광범위한 행동을 획득할 수 있는 유연한 단일 알고리즘이 있다면

90
00:08:33,919 --> 00:08:37,839
그 알고리즘은 아마도 강화 학습 알고리즘처럼 보일 것입니다.

91
00:08:37,839 --> 00:08:43,519
그리고 아마도 딥 모델과 같은 대용량 표현을 갖추고 있을 것입니다.

92
00:08:43,519 --> 00:08:45,839
그러면 딥 러닝과 rl이 지금 잘할 수 있는 것이 무엇인지 잘 말할 수 있습니다.

93
00:08:45,839 --> 00:08:47,440
기본적으로 우리는 그것에 얼마나 가까이 왔을까요?

94
00:08:47,440 --> 00:08:49,600
그리고 무엇이 부족할까요?

95
00:08:49,600 --> 00:08:52,080
현재의 심층 강화 학습 알고리즘은 어떤 것에는 꽤 능숙합니다.

96
00:08:52,080 --> 00:08:55,440
그것은 높은 수준의 기술을 습득하거나

97
00:08:55,440 --> 00:08:59,920
보드 게임 및 비디오 게임과 같이 알려진 간단한 규칙이 적용되는 도메인에 능숙합니다.

98
00:08:59,920 --> 00:09:03,200
그것은 원시 감각 입력으로 간단한 기술을 배우는 데 능숙합니다.

99
00:09:03,200 --> 00:09:05,279
충분한 경험을 준다면요

100
00:09:05,279 --> 00:09:10,560
그리고 그들은 충분히 인간이 제공한 전문가 행동을 모방하는 법을 배우는 데 능숙합니다.

101
00:09:10,560 --> 00:09:16,480
그러나 그들은 여전히 인간 지능이나 동물 지능에 비해 몇 가지 매우 중요한 면에서 부족합니다.

102
00:09:16,480 --> 00:09:18,720
인간은 엄청나게 빨리 배울 수 있습니다

103
00:09:18,720 --> 00:09:21,279
심층 강화 학습 알고리즘은 일반적으로 효율성으로 알려져 있지 않습니다.

104
00:09:21,279 --> 00:09:24,240
그것은 일반적으로 매우 많은 경험을 필요로 합니다

105
00:09:24,240 --> 00:09:28,240
인간이 과거 지식을 매우 잘 활용하기 때문일 수 있습니다.

106
00:09:28,240 --> 00:09:30,240
그래서 인간은 빠르게 적응할 수 있습니다.

107
00:09:30,240 --> 00:09:34,399
예를 들어 이것은 사람이 나무 조각을 움직이는 일반적으로 수행되는 운동 제어 실험입니다.

108
00:09:34,399 --> 00:09:37,680
사람이 반응해야 하는 방해가 생깁니다.

109
00:09:37,680 --> 00:09:46,800
그런 다음 실험자는 인간이 몇 번의 시도에서 나무 조각에 가해진 방해를 극복하는 방법을 배우기 위해 얼마나 많은 시도를 해야 하는지 측정합니다.

110
00:09:46,800 --> 00:09:55,600
그러나 인간은 신체를 움직이는 물리적 조작과 방해의 힘에 반응하는 과거 경험이 있는 처음부터 완전히 배우지 않을 가능성이 있습니다.

111
00:09:55,600 --> 00:09:58,640
심층 강화학습에서의 전이 학습은 여전히 미해결 문제입니다.

112
00:09:58,640 --> 00:10:02,560
그러나 목표는 본질적으로 이 기능을 구현하는 것입니다.

113
00:10:02,560 --> 00:10:06,160
또한 실제로는 보상 기능이 무엇인지 명확하지 않은 경우가 많습니다.

114
00:10:06,160 --> 00:10:14,560
그래서 고전적인 강화 학습에서 우리는 일반적으로 보상 함수가 알려져 있고 정확하다고 가정하지만 실제 세계에서는 훨씬 덜 명확합니다.

115
00:10:14,560 --> 00:10:22,079
또한 예측의 역할이 무엇인지 명확하지 않으므로 전 세계를 모델링한 다음 해당 모델을 통해 계획하여 학습해야 합니다.

116
00:10:22,079 --> 00:10:24,079
아니면 시행착오를 통해 직접 배워야 할까요?

117
00:10:24,079 --> 00:10:27,760
아니면 둘 다 조금 해야 합니까

118
00:10:27,760 --> 00:10:30,800
하지만 이 모든 것을 요약하자면

119
00:10:30,800 --> 00:10:44,720
심층 강화 학습이 우리에게 잠재적으로 제공할 수 있는 것 중 하나는 개별 알고리즘이나 개별 모듈을 설계할 필요 없이 보다 통합된 알고리즘 방식으로 지능 획득에 대해 생각할 수 있는 방법입니다.

120
00:10:44,720 --> 00:10:56,000
그러나 이것은 이러한 종류의 매우 복잡한 모듈식 모델에서 단순한 학습 주도 모델로 가는 새로운 아이디어가 결코 아닙니다. 어떤 의미에서는 컴퓨터 과학 자체만큼 오래된 것입니다.

121
00:10:56,000 --> 00:11:02,320
성인의 마음을 시뮬레이션하는 프로그램을 만드는 대신 이 주제에 대해 제가 아주 좋아하는 인용문이 있습니다.

122
00:11:02,320 --> 00:11:11,680
적절한 교육 과정을 거치면 성인의 두뇌를 얻을 수 있는 어린이를 시뮬레이션하는 것을 제작하려고 하지 않는 이유는 무엇입니까?

123
00:11:11,680 --> 00:11:13,600
누가 이 글을 썼냐고요?

124
00:11:13,600 --> 00:11:16,320
앨런 튜링

